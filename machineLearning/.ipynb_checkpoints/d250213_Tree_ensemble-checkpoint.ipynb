{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9629037e",
   "metadata": {},
   "source": [
    "## **트리의 앙상블**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9480d346",
   "metadata": {},
   "source": [
    "### 정형 데이터와 비정형 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca1dc4d",
   "metadata": {},
   "source": [
    "## **랜덤포레스트**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da7db9a",
   "metadata": {},
   "source": [
    "- 부트스트랩 샘플 : 데이터세트에서 중복을 허용하여 데이터를 샘플링하는 방식\n",
    "- 각 노드를 분할할 때 전체 특성 중에서 일부 특성을 무작위로 고른 다음 이 중에서 최선의 분할을 찾는다. 분류 모델인 RandomForestCClassifier 는  기본적으로 전체 특성 개수의 제곱근만큼의 특성을 선택, 회귀 모델인 RandomForestRegressor는 전체 특성 사용\n",
    "- 사이킷런의 랜덤 포레스트는 기본적으로 100개의 결정 트리를 이런 방식으로 훈련, 그 다음 분류일 때는 각 트리의 클래스별 확률을 평균하여 가장 높은 확률을 가진 클래스를 예측으로 삼는다. 회귀일 때는 단순히 각 트리의 예측을 평균"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3925a423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>sugar</th>\n",
       "      <th>pH</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  sugar    pH  class\n",
       "0      9.4    1.9  3.51    0.0\n",
       "1      9.8    2.6  3.20    0.0\n",
       "2      9.8    2.3  3.26    0.0\n",
       "3      9.8    1.9  3.16    0.0\n",
       "4      9.4    1.9  3.51    0.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 라이브러리 임포트, wine.csv 파일 로딩해서 class 열은 target으로 나머지는 data 로 array로 저장하고 테스트셋 20%로 분리\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('data/wine.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f726eb-88b9-4b34-bf87-b1cd08a79472",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['alcohol', 'sugar', 'pH']].to_numpy()\n",
    "target = df['class'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6af7519-a1a9-4c04-8478-10fbea054cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a978923-1c91-4621-b368-a1848bee232d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5197, 3)\n",
      "(5197,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34054023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9973541965122431 0.8905151032797809\n"
     ]
    }
   ],
   "source": [
    "# RandomForestClassifier 클래스를 이용해서 교차검증을 하고 cross_validate 함수의 return_train_score 파라미터를 True로 지정해서 \n",
    "# 훈련세트에 대한 점수도 리턴받을 수 있음\n",
    "# 교차검증으로 리터받은 값 중에서 train_score 키 와 test_score 키의 값을 평균해서 출력하면 성능을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3fa7d82-3b0c-4587-b35a-74eba8ea6384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5c73627-9e23-47f6-909f-766c554eb349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9973541965122431 0.8905151032797809\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "scores = cross_validate(rf, X_train, y_train, return_train_score=True)\n",
    "train_score = scores['train_score'].mean()\n",
    "test_score = scores['test_score'].mean()\n",
    "print(train_score, test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cad12b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.21853065, 0.20890498, 0.22247434, 0.21146321, 0.21719027]),\n",
       " 'score_time': array([0.03378844, 0.02819133, 0.02878976, 0.02782059, 0.03214669]),\n",
       " 'test_score': array([0.88461538, 0.88942308, 0.90279115, 0.88931665, 0.88642926]),\n",
       " 'train_score': array([0.9971133 , 0.99663219, 0.9978355 , 0.9973545 , 0.9978355 ])}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위에서 교차검증으로 리턴받은 scores 값 출력\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "62149872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23167441, 0.50039841, 0.26792718])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤포레스트 모델 학습\n",
    "# 특성 중요도 출력\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=42, oob_score=True)\n",
    "rf.fit(X_train, y_train)\n",
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "74f0de92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8934000384837406"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OOB(Out Of Bag) - 부트스트랩 샘플에 포함되지 않은 샘플\n",
    "# OOB를 검증세트처럼 사용하기 위해 랜덤포레스트 객체 생성시 oob_score=True 파라미터를 지정해서 검증\n",
    "rf.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbd3c51",
   "metadata": {},
   "source": [
    "## 엑스트라 트리\n",
    "- 랜덤 포레스트와 매우 비슷하게 동작\n",
    "- 기본적으로 100개의 결정 트리를 훈련\n",
    "\n",
    "- 랜덤 포레스트와 엑스트라 트리의 차이점은 부트스트랩 샘플을 사용하지 않는다는 점이다. 즉, 각 결정트리를 만들 때 전체 훈련 세트를 사용한다. 대신 노드를 분할할 때 가장 좋은 분할을 찾는것이 아니라 무작위로 분할한다.\n",
    "- DecisionTreeClassifier의 splitter 매개변수를 'random'으로 지정하는 것이 엑스트라 트리이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f540d79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9974503966084433 0.8887848893166506\n"
     ]
    }
   ],
   "source": [
    "# 엑스트라트리 임포트, 생성, 교차검증, score 평균값 출력\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
    "scores = cross_validate(et, X_train, y_train, return_train_score=True, n_jobs=-1)\n",
    "print(scores['train_score'].mean(), scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa116c53",
   "metadata": {},
   "source": [
    "- 보통 엑스트라 트리가 무작위성이 좀 더 크기 때문에 랜덤 포레스트보다 더 많은 결정 트리를 훈련해야 한다. 하지만 랜덤하게 노드를 분할하기 때문에 빠른 계산 속도가 엑스트라 트리의 장점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "962f3f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20183568, 0.52242907, 0.27573525])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 엑스트라트리 학습하고 특성 중요도 출력\n",
    "et.fit(X_train, y_train)\n",
    "et.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365e4331",
   "metadata": {},
   "source": [
    "### 그레이디언트 부스팅\n",
    "- 깊이가 얕은 결정 트리를 사용하여 이전 트리의 오차를 보완하는 방식으로 앙상블 학습\n",
    "- 사이킷런의 GradientBoostingClassifier는 기본적으로 깊이가 3인 결정 트리를 100개 사용\n",
    "- 깊이가 얕은 결정 트리를 사용하기 때문에 과대적합에 강하고 일반적으로 높은 일반화 성능을 기대할 수 있다.\n",
    "- 경사하강법을 사용하여 트리를 앙상블에 추가, 분류에서는 로지스틱 손실 함수를 사용하고 회귀에서는 평균 제곱 오차함수를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8b31b488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8881086892152563 0.8720430147331015\n"
     ]
    }
   ],
   "source": [
    "# 그레이디언트부스팅 임포트, 생성, 교차검증, score 평균값 출력\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "scores = cross_validate(gb, X_train, y_train, return_train_score=True, n_jobs=-1)\n",
    "print(scores['train_score'].mean(), scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "24f65952-a928-4776-a7de-6313b7179ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9464595437171814 0.8780082549788999\n"
     ]
    }
   ],
   "source": [
    "# 결정트리의 개수를 500개로 늘리고 학습률을 20%로 지정해서 그레이디언트부스팅 생성하고 교차검증, score 평균값 출력\n",
    "gb = GradientBoostingClassifier(n_estimators=500, learning_rate=0.2, random_state=42)\n",
    "scores = cross_validate(gb, X_train, y_train, return_train_score=True, n_jobs=-1)\n",
    "print(scores['train_score'].mean(), scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "551aef06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15882696, 0.6799705 , 0.16120254])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그레이디언트부스팅 학습하고 특성 중요도 출력\n",
    "gb.fit(X_train, y_train)\n",
    "gb.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1412927e",
   "metadata": {},
   "source": [
    "### 히스토그램 기반 그레이디언트 부스팅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eb4d46-1444-484d-b2f8-9c26c7b0a2e9",
   "metadata": {},
   "source": [
    "- 입력 특성을 256개의 구간으로 나누고 나눈 구간 중에서 하나를 떼어 놓고 누락된 값을 위해서 사용하기 때문에 누락된 특성에 대한\n",
    "  전처리가 필요 없고 노드를 분할할 때 최적의 분할을 매우 빠르게 찾을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "38f32715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9321723946453317 0.8801241948619236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "# 그레이디언트부스팅 임포트, 생성, 교차검증, score 평균값 출력\n",
    "hg = HistGradientBoostingClassifier(random_state=42)\n",
    "scores = cross_validate(hg, X_train, y_train, return_train_score=True)\n",
    "print(scores['train_score'].mean(), scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "8f97c85c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'importances_mean': array([0.05969231, 0.20238462, 0.049     ]), 'importances_std': array([0.004     , 0.007938  , 0.00453846]), 'importances': array([[0.06230769, 0.05769231, 0.05538462, 0.05538462, 0.06076923,\n",
      "        0.06076923, 0.06846154, 0.06230769, 0.05461538, 0.05923077],\n",
      "       [0.20076923, 0.2       , 0.21153846, 0.20076923, 0.20307692,\n",
      "        0.18923077, 0.19615385, 0.19461538, 0.21384615, 0.21384615],\n",
      "       [0.05692308, 0.04692308, 0.05076923, 0.04769231, 0.04692308,\n",
      "        0.05      , 0.04384615, 0.04692308, 0.04307692, 0.05692308]])}\n"
     ]
    }
   ],
   "source": [
    "# 히스토그램 기반 그레이디언트 부스팅은 특성 중요도를 계산할 때 permutation_importance 함수를 임포트하고 사용\n",
    "from sklearn.inspection import permutation_importance\n",
    "hg.fit(X_train, y_train)\n",
    "pi = permutation_importance(hg, X_test, y_test, random_state=42, n_jobs=-1, n_repeats=10 )\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "cb9ebf7c-97c9-4f43-8324-13d53168c394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05969231, 0.20238462, 0.049     ])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트 셋에 대해서 특성 중요도 출력\n",
    "pi.importances_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "3b1352ec-5479-4f3a-b74c-b0ffae343af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8723076923076923"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트셋의 score 값 출력\n",
    "hg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e9f29fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05969231 0.20238462 0.049     ]\n"
     ]
    }
   ],
   "source": [
    "# 테스트 셋에 대해서 특성 중요도 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdcda091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8723076923076923"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 테스트셋의 score 값 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4357ca57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
