{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c6fc965-ca47-46d7-a489-09e135cce68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu118\n",
      "True\n",
      "11.8\n",
      "NVIDIA GeForce RTX 3050\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())  # CUDA가 활성화 여부\n",
    "print(torch.version.cuda)  # 설치된 CUDA 버전 출력\n",
    "print(torch.cuda.get_device_name(0))  # 사용 중인 GPU\n",
    "print(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0411ec3-f8c6-47d9-8ccd-883e0e522592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('data/train_dataset.csv')\n",
    "test_df = pd.read_csv('data/test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "739ed61f-7382-403e-8bb5-7c41a8ebcc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text emotion situation\n",
      "0  일은 왜 해도 해도 끝이 없을까? 화가 난다. 그냥 내가 해결하는 게 나아. 남들한...     E18       S06\n",
      "1  이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나....     E18       S06\n",
      "2  회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...     E18       S06\n",
      "3  직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...     E18       S06\n",
      "4  얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나. 상사인 나에게 ...     E18       S06\n",
      "                                                text emotion situation\n",
      "0  이번 프로젝트에서 발표를 하는데 내가 실수하는 바람에 우리 팀이 감점을 받았어. 너...     E31       S06\n",
      "1  회사에서 중요한 프로젝트를 혼자 하게 됐는데 솔직히 두렵고 무서워. 나에게 너무 크...     E31       S06\n",
      "2  상사가 너무 무섭게 생겨서 친해지는 게 너무 두려워. 무섭게 생겼는데도 업무를 보려...     E31       S06\n",
      "3  이번에 힘들게 들어간 첫 직장이거든. 첫 직장이라서 그런지 너무 긴장된다. 첫 직장...     E31       S06\n",
      "4  직장에서 동료들이랑 관계가 안 좋아질까 봐 걱정돼. 내가 낯가림이 심해서 친해질 수...     E31       S06\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fd70f052-fbc1-498a-8dc0-92be2607d64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51628 entries, 0 to 51627\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       51628 non-null  object\n",
      " 1   emotion    51628 non-null  object\n",
      " 2   situation  51628 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.2+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6640 entries, 0 to 6639\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       6640 non-null   object\n",
      " 1   emotion    6640 non-null   object\n",
      " 2   situation  6640 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 155.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_df.info())\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "55e925ae-adce-4e93-b162-bfd31b3323e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "오버샘플링된 데이터 (pre_train_df):\n",
      "                                                text emotion situation\n",
      "0  [일은, 해도, 끝이, 없을까, 화가, 난다, 그냥, 내가, 해결하는, 나아, 남들...     E18       S06\n",
      "1  [화가, 이번, 달에, 급여가, 깎였어, 물가는, 오르는데, 월급만, 자꾸, 깎이니...     E18       S06\n",
      "2  [같아, 회사에, 신입이, 들어왔는데, 말투가, 거슬려, 그런, 애를, 매일, 봐야...     E18       S06\n",
      "3  [직장에서, 막내라는, 이유로, 나에게만, 온갖, 심부름을, 시켜, 일도, 많은, ...     E18       S06\n",
      "4  [화가, 내가, 너무, 매일, 얼마, 입사한, 신입사원이, 나를, 무시하는, 같아서...     E18       S06\n",
      "\n",
      "오버샘플링 후 감정 클래스 분포: Counter({'E18': 3288, 'E66': 3288, 'E37': 3288, 'E35': 3288, 'E50': 3288, 'E25': 3288, 'E64': 3288, 'E42': 3288, 'E49': 3288, 'E56': 3288, 'E10': 3288, 'E30': 3288, 'E22': 3288, 'E40': 3288, 'E19': 3288, 'E32': 3288, 'E20': 3288, 'E62': 3288, 'E68': 3288, 'E21': 3288, 'E15': 3288, 'E16': 3288, 'E67': 3288, 'E47': 3288, 'E54': 3288, 'E26': 3288, 'E53': 3288, 'E24': 3288, 'E51': 3288, 'E12': 3288, 'E23': 3288, 'E57': 3288, 'E58': 3288, 'E69': 3288, 'E60': 3288, 'E11': 3288, 'E52': 3288, 'E36': 3288, 'E55': 3288, 'E59': 3288, 'E39': 3288, 'E65': 3288, 'E44': 3288, 'E43': 3288, 'E33': 3288, 'E63': 3288, 'E14': 3288, 'E41': 3288, 'E31': 3288, 'E27': 3288, 'E13': 3288, 'E38': 3288, 'E28': 3288, 'E29': 3288, 'E46': 3288, 'E61': 3288, 'E17': 3288, 'E48': 3288, 'E34': 3288, 'E45': 3288})\n",
      "\n",
      "오버샘플링 후 상황 클래스 분포: Counter({'S06': 16440, 'S04': 16440, 'S05': 16440, 'S08': 16440, 'S13': 16440, 'S11': 16440, 'S02': 16440, 'S03': 16440, 'S10': 16440, 'S07': 16440, 'S01': 16440, 'S09': 16440})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# 텍스트 데이터를 TF-IDF 벡터로 변환\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(train_df['text'])\n",
    "\n",
    "# 'emotion'과 'situation'을 결합하여 새로운 라벨을 만듭니다.\n",
    "train_df['combined_label'] = train_df['emotion'] + \"_\" + train_df['situation']\n",
    "\n",
    "# 결합된 라벨\n",
    "y_combined = train_df['combined_label']\n",
    "\n",
    "# SMOTE 오버샘플링 (소수 클래스 오버샘플링)\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_smote, y_smote = smote.fit_resample(X, y_combined)\n",
    "\n",
    "# 오버샘플링 후 라벨을 'emotion'과 'situation'으로 분리\n",
    "y_smote_emotion, y_smote_situation = zip(*[label.split('_') for label in y_smote])\n",
    "\n",
    "# 오버샘플링된 데이터로 새로운 데이터프레임 생성\n",
    "pre_train_df = pd.DataFrame({\n",
    "    'text': vectorizer.inverse_transform(X_smote),\n",
    "    'emotion': y_smote_emotion,\n",
    "    'situation': y_smote_situation\n",
    "})\n",
    "\n",
    "# 오버샘플링된 데이터프레임 확인\n",
    "print(\"\\n오버샘플링된 데이터 (pre_train_df):\")\n",
    "print(pre_train_df.head())\n",
    "\n",
    "# 오버샘플링 후 감정 클래스 분포 확인\n",
    "print(f\"\\n오버샘플링 후 감정 클래스 분포: {Counter(y_smote_emotion)}\")\n",
    "\n",
    "# 오버샘플링 후 상황 클래스 분포 확인\n",
    "print(f\"\\n오버샘플링 후 상황 클래스 분포: {Counter(y_smote_situation)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6340abbe-41c4-4486-8198-b3edd4d03b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 197280 entries, 0 to 197279\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   text       197280 non-null  object\n",
      " 1   emotion    197280 non-null  object\n",
      " 2   situation  197280 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 4.5+ MB\n"
     ]
    }
   ],
   "source": [
    "pre_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "12b33529-4272-4823-9563-39e0b0115f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 행의 텍스트 리스트에 대해 단어들을 공백으로 연결하여 문장으로 만듦\n",
    "pre_train_df['text'] = pre_train_df['text'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fd42fcaf-e03b-4e0c-9e06-d8bf4531407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pre_train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "177158dc-c313-45c7-9972-3fbda190faaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>situation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>일은 해도 끝이 없을까 화가 난다 그냥 내가 해결하는 나아 남들한테 부담 주고 싶지...</td>\n",
       "      <td>E18</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>화가 이번 달에 급여가 깎였어 물가는 오르는데 월급만 자꾸 깎이니까 너무 최대한 지...</td>\n",
       "      <td>E18</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>같아 회사에 신입이 들어왔는데 말투가 거슬려 그런 애를 매일 봐야 한다고 생각하니까...</td>\n",
       "      <td>E18</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜 일도 많은 정말 분하고 섭섭해...</td>\n",
       "      <td>E18</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>화가 내가 너무 매일 얼마 입사한 신입사원이 나를 무시하는 같아서 상사인 나에게 먼...</td>\n",
       "      <td>E18</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotion situation\n",
       "0  일은 해도 끝이 없을까 화가 난다 그냥 내가 해결하는 나아 남들한테 부담 주고 싶지...     E18       S06\n",
       "1  화가 이번 달에 급여가 깎였어 물가는 오르는데 월급만 자꾸 깎이니까 너무 최대한 지...     E18       S06\n",
       "2  같아 회사에 신입이 들어왔는데 말투가 거슬려 그런 애를 매일 봐야 한다고 생각하니까...     E18       S06\n",
       "3  직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜 일도 많은 정말 분하고 섭섭해...     E18       S06\n",
       "4  화가 내가 너무 매일 얼마 입사한 신입사원이 나를 무시하는 같아서 상사인 나에게 먼...     E18       S06"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head() # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "34ee6dfe-8c62-428d-961b-e752d4f8cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab\n",
    "\n",
    "# mecabrc 경로를 명확하게 지정\n",
    "mecab = MeCab.Tagger(\"-r C:/mecab/etc/mecabrc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5d6c80f3-2168-4024-979c-c090c6fe4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# 한국어 불용어 리스트 가져오기\n",
    "url = \"https://raw.githubusercontent.com/stopwords-iso/stopwords-ko/master/stopwords-ko.txt\"\n",
    "response = requests.get(url)\n",
    "korean_stopwords = set(response.text.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40a4b01a-a6d2-4a04-83dd-c30c6638c5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_text_with_adverbs_and_verbs(text):\n",
    "#     # 텍스트가 비어있는 경우\n",
    "#     if not isinstance(text, str):  \n",
    "#         return \"\"\n",
    "    \n",
    "#     parsed_text = mecab.parse(text).split(\"\\n\")[:-2]  # 마지막 줄(EOS, 공백) 제거\n",
    "#     tokens = [line.split(\"\\t\") for line in parsed_text if \"\\t\" in line]\n",
    "    \n",
    "#     # 품사 필터링 (명사, 형용사, 부사, 동사만 남기기)\n",
    "#     keywords = []\n",
    "#     for token in tokens:\n",
    "#         if len(token) < 2:\n",
    "#             continue\n",
    "#         word, features = token[0], token[1].split(\",\")\n",
    "#         tag = features[0]  \n",
    "#         lemma = features[-3]  # 원형을 추출\n",
    "\n",
    "#         # 명사(NNG, NNP) 그대로 추가\n",
    "#         if tag in ['NNG', 'NNP']:\n",
    "#             keywords.append(word)\n",
    "\n",
    "#         # 형용사(VA) 원형 변환 및 추가, 원형 변환이 안되면 제외\n",
    "#         elif tag == 'VA':\n",
    "#             if lemma != '*' and lemma != '' and lemma != word:\n",
    "#                 keywords.append(lemma)\n",
    "#             # 형용사의 경우 원형 변환이 안 되면 제외\n",
    "#             else:\n",
    "#                 continue\n",
    "\n",
    "#         # 부사(MAG)는 감정의 강도나 상태를 강조하므로 추가\n",
    "#         elif tag == 'MAG':  # 부사 태그\n",
    "#             keywords.append(word)\n",
    "        \n",
    "#         # 동사(VV) 원형 변환 및 추가, 원형 변환이 안되면 제외\n",
    "#         elif tag == 'VV':  # 동사 태그\n",
    "#             if lemma != '*' and lemma != '' and lemma != word:\n",
    "#                 keywords.append(lemma)\n",
    "#             # 동사의 경우 원형 변환이 안 되면 제외\n",
    "#             else:\n",
    "#                 continue\n",
    "\n",
    "#     # 중복 단어 제거 & 불용어 제거\n",
    "#     keywords = list(dict.fromkeys(keywords))  # 중복 제거\n",
    "#     keywords = [word for word in keywords if word not in korean_stopwords and len(word) > 1]  # 불용어 제거\n",
    "    \n",
    "#     return \" \".join(keywords)\n",
    "\n",
    "# # MeCab 적용하여 텍스트 전처리\n",
    "# train_df['text'] = train_df['text'].apply(preprocess_text_with_adverbs_and_verbs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20e90f66-2c13-4cf4-97a5-9c1804c59466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df['text'].loc[51:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ae3a5dba-ab12-4067-85dc-d39a7cd08ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 197280/197280 [29:54<00:00, 109.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Okt 객체 초기화\n",
    "okt = Okt()\n",
    "\n",
    "# 진행 상황 표시를 위해 tqdm을 활성화\n",
    "tqdm.pandas()\n",
    "\n",
    "def preprocess_text_with_okt(text):\n",
    "    if not isinstance(text, str):  # NaN 처리\n",
    "        return \"\"\n",
    "    \n",
    "    # 형태소 분석\n",
    "    parsed_text = okt.pos(text)\n",
    "    \n",
    "    keywords = []\n",
    "    for word, tag in parsed_text:\n",
    "        # 명사(NNG, NNP) 그대로 추가\n",
    "        if tag in ['Noun', 'NNP']:\n",
    "            keywords.append(word)\n",
    "        \n",
    "        # 형용사 원형 추가\n",
    "        elif tag == 'Adjective':\n",
    "            keywords.append(word)  # '형용사'는 원형이 해당 형태\n",
    "        \n",
    "        # 동사 원형 추가\n",
    "        elif tag == 'Verb':\n",
    "            keywords.append(word)  # '동사'도 원형이 해당 형태\n",
    "        \n",
    "        # 부사 추가\n",
    "        elif tag == 'Adverb':\n",
    "            keywords.append(word)\n",
    "    \n",
    "    # 중복 단어 제거 및 불용어 제거\n",
    "    keywords = list(dict.fromkeys(keywords))  # 중복 제거\n",
    "    keywords = [word for word in keywords if word not in korean_stopwords and len(word) > 1]  # 불용어 제거\n",
    "    \n",
    "    return \" \".join(keywords)\n",
    "\n",
    "# 진행상황을 표시하며 apply 적용\n",
    "train_df['text'] = train_df['text'].progress_apply(preprocess_text_with_okt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "eb46e224-3d12-4fe2-a9d3-9a0474630413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>situation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>너무 정말 하는데 많이 요즘 취업 해야 없어서 걱정 모르겠어 구직 자리 슬퍼 살아야...</td>\n",
       "      <td>E20</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>같아 않아서 좋은 많이 요즘 취업 좋지 시장 직장 없는 지원 곳도 떨어지고 막막해</td>\n",
       "      <td>E20</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>너무 같아 취업 회사 다시는 슬퍼 해고 당했어</td>\n",
       "      <td>E20</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>한다고 직장 이제 막막해 가깝게 지내던 퇴사 했어 입사 가르쳐 주셨던 나가야 생각 하니</td>\n",
       "      <td>E20</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>너무 같아 정말 않아서 고민 않는 진로 요즘 때문 속상해 해야 취업 문제 많아 울적...</td>\n",
       "      <td>E20</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>너무 슬퍼 없는 떨어지고 고객 폭언 자존감 사람 감정 사람인 참을 상황 이르</td>\n",
       "      <td>E20</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>많이 열심히 됐어 슬퍼 올해 진급 예정 이었는데 기대 해서인지 실망 크네 하다 보면...</td>\n",
       "      <td>E20</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>같아서 면접 취업 봤는데 모르겠어 슬퍼 망친 떨어지면 어떡하지</td>\n",
       "      <td>E20</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>너무 회사 코로나바이러스 때문 이럴 하고 슬퍼 해고 됐어 먹고 자려고 했던 운동</td>\n",
       "      <td>E20</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>같아 회사 오늘 입사 면접 봤어 취업 있겠어</td>\n",
       "      <td>E62</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>자꾸 같아 나를 회사 신뢰 하는 그건 기분 당연히 업무 처리 해서지 선지 늘어나네</td>\n",
       "      <td>E62</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>나를 먼저 면접 같은 사람 취업 선배 비결 알려 줬어 보러 가는데 든든해 태도 일반...</td>\n",
       "      <td>E62</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>너무 직장 사람 상사 칭찬 받았는데 실수 깔끔하게 처리 해서 받았어</td>\n",
       "      <td>E68</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>너무 싶어 부모님 취업 해서 받아서 월급 용돈 드리고</td>\n",
       "      <td>E68</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>해야겠어 오늘 열심히 사장 칭찬 받아서 매우 기뻐 직원 이름 부르셨거든</td>\n",
       "      <td>E68</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>회사 정말 이제 열심히 가고 매우 기뻐 지난주 싶던 원서 접수 했는데 합격 했어 면...</td>\n",
       "      <td>E68</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>너무 같아 들어 마음 면접 다시 열심히 떨어져서 준비 해서 봤던 실망 탈락 경험 도...</td>\n",
       "      <td>E21</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>너무 이제 하고 있을까 면접 실패 취직 해서 결혼 한다는데 걱정 있다니 실망 스러워</td>\n",
       "      <td>E21</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>정말 회사 갈수록 새로 취업 실망 스러워 처음 좋았는데 별로 일이 사람 전체</td>\n",
       "      <td>E21</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>화가 같아 정말 회사 면접 만드는 좋지 떨어뜨린 물건 사지 않을 인재 알아본 나쁜 분명</td>\n",
       "      <td>E15</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>같아 직장 여성 직원 이유 연봉 올려주지 않겠대 미혼 경우 심한</td>\n",
       "      <td>E15</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>직장 들어 대해 있어 노력 걱정 기간 감정 어릴 명확하게 가지 분야 진로 설정 해왔...</td>\n",
       "      <td>E15</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>같아 느껴져 회사 같은 기분 생길 따돌림 당하는 뭔가 업무 분담 악의 변호사 만나 ...</td>\n",
       "      <td>E15</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>너무 회사 취업 싶은 마음 빨리 발표 이렇게 나네 보고 좋겠어 모르겠어 하고 원서 ...</td>\n",
       "      <td>E16</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>싶어 취업 빨리 해서 가고 하고 싶다 벌고 월급 받으면 자동차 사고 여행 저축</td>\n",
       "      <td>E16</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>좋은 기다리고 면접 연락 없어서 좋겠어 있는데 결과 초조해 소식 있었으면</td>\n",
       "      <td>E16</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>회사 부모님 취업 해서 원하는 드디어 했어 그동안 죄송한 마음 들고 걱정 컸는데 한...</td>\n",
       "      <td>E67</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>같아 매일 업무 되나 괜히 했는데 해서 상사 그게 보고 하라 인제 와서 그러는 억울...</td>\n",
       "      <td>E47</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>회사 싶어 먼저 느껴져 좋은 다시 준비 해서 취업 친구 잊고 먹고 취직 했어 학교 ...</td>\n",
       "      <td>E54</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>같아 취업 친구 우울해 준비 되어 진작 했는데 나서</td>\n",
       "      <td>E54</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>정말 아직도 시험 대학 졸업 공무원 준비 붙지도 부족해</td>\n",
       "      <td>E26</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>면접 없어 좋겠어 없고 있으니 있었으면 이력서 여러 넣었지만 연락 오는 복도 없나 ...</td>\n",
       "      <td>E26</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>같아 회사 계속 없고 하게 요새 끝나고 오면 피곤해서 친구 보기 귀찮고 휴대전화 되...</td>\n",
       "      <td>E53</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>있지만 때문 코로나 갈수록 계속 준비 취업 하기 초조해 가뜩이나 어려운데 힘들어졌어...</td>\n",
       "      <td>E16</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>친한 해서 친구 있어 가장 사업 한다고 투자 했는데 파업 연락 없이 떠나 버렸어 법...</td>\n",
       "      <td>E42</td>\n",
       "      <td>S04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>받고 가족 맞나 생각 하더군 상처</td>\n",
       "      <td>E40</td>\n",
       "      <td>S04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>갑자기 열심히 취업 준비 간절한 마음 빠지네 하반기 좁아진다는 기사 보니 우울해지네</td>\n",
       "      <td>E24</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>화가 너무 하는 있지만 상사 달라 해서 참고 처리 동기 이상하게 먹어 지금 계속 되...</td>\n",
       "      <td>E15</td>\n",
       "      <td>S04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>때문 해야 해서 사람 됐어 하던 혼났는데 사과 어색한 사이 받아줄까</td>\n",
       "      <td>E51</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>너무 같아 그런 없어 능력 걱정 하고 보니 이러다가는 평생 연애 결혼 하는 드는 비...</td>\n",
       "      <td>E12</td>\n",
       "      <td>S05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>너무 나도 생각 갑자기 대해 있어 그동안 없이 결혼 친구 부끄러워하는 부끄럽네 아무...</td>\n",
       "      <td>E56</td>\n",
       "      <td>S05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>달라 취업 해서 생각 있는 있어 해야지 졸업 남았는데 캄캄해 전공 살릴 하면 좋겠다...</td>\n",
       "      <td>E24</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>같아 싶어 직업 해야 점점 보육 교사 힘들어지는 우울하네 보수 적고 힘들고</td>\n",
       "      <td>E24</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>나도 하는 아니야 엄마 모르겠어 있거든 위해 결혼 아내 매일 잔소리 사는 물건 작은...</td>\n",
       "      <td>E23</td>\n",
       "      <td>S05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>대한 생겨 걱정 결혼 준비 행복했는데 날짜 다가올수록 초조해지고 불안해져 막연한 두...</td>\n",
       "      <td>E30</td>\n",
       "      <td>S05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>자꾸 같아 않아 아직 있을 결혼 코앞 확신 들지 도망치려는 싫어져 여자친구 이야기 ...</td>\n",
       "      <td>E57</td>\n",
       "      <td>S05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>자꾸 너무 그런 달라 하는 결혼 생기 좋을 알았는데 없었어 들어가면 놀아 지쳐 한심해</td>\n",
       "      <td>E58</td>\n",
       "      <td>S05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>너무 하는데 근데 준비 결혼 하려고 친구 비교 되네 비슷한 시기 거든 과정 달라</td>\n",
       "      <td>E54</td>\n",
       "      <td>S05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>같아 질문 면접 오늘 준비 봤는데 네이버 인턴 봐도 나와서 대로 가진 장점 어필 있...</td>\n",
       "      <td>E69</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>진짜 좋겠어 기뻐 결혼 낳았어 아내 건강했으면</td>\n",
       "      <td>E60</td>\n",
       "      <td>S05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text emotion situation\n",
       "51   너무 정말 하는데 많이 요즘 취업 해야 없어서 걱정 모르겠어 구직 자리 슬퍼 살아야...     E20       S06\n",
       "52       같아 않아서 좋은 많이 요즘 취업 좋지 시장 직장 없는 지원 곳도 떨어지고 막막해     E20       S06\n",
       "53                           너무 같아 취업 회사 다시는 슬퍼 해고 당했어     E20       S06\n",
       "54    한다고 직장 이제 막막해 가깝게 지내던 퇴사 했어 입사 가르쳐 주셨던 나가야 생각 하니     E20       S06\n",
       "55   너무 같아 정말 않아서 고민 않는 진로 요즘 때문 속상해 해야 취업 문제 많아 울적...     E20       S06\n",
       "56          너무 슬퍼 없는 떨어지고 고객 폭언 자존감 사람 감정 사람인 참을 상황 이르     E20       S06\n",
       "57   많이 열심히 됐어 슬퍼 올해 진급 예정 이었는데 기대 해서인지 실망 크네 하다 보면...     E20       S06\n",
       "58                  같아서 면접 취업 봤는데 모르겠어 슬퍼 망친 떨어지면 어떡하지     E20       S06\n",
       "59        너무 회사 코로나바이러스 때문 이럴 하고 슬퍼 해고 됐어 먹고 자려고 했던 운동     E20       S06\n",
       "60                            같아 회사 오늘 입사 면접 봤어 취업 있겠어     E62       S06\n",
       "61       자꾸 같아 나를 회사 신뢰 하는 그건 기분 당연히 업무 처리 해서지 선지 늘어나네     E62       S06\n",
       "62   나를 먼저 면접 같은 사람 취업 선배 비결 알려 줬어 보러 가는데 든든해 태도 일반...     E62       S06\n",
       "63               너무 직장 사람 상사 칭찬 받았는데 실수 깔끔하게 처리 해서 받았어     E68       S06\n",
       "64                       너무 싶어 부모님 취업 해서 받아서 월급 용돈 드리고     E68       S06\n",
       "65             해야겠어 오늘 열심히 사장 칭찬 받아서 매우 기뻐 직원 이름 부르셨거든     E68       S06\n",
       "66   회사 정말 이제 열심히 가고 매우 기뻐 지난주 싶던 원서 접수 했는데 합격 했어 면...     E68       S06\n",
       "67   너무 같아 들어 마음 면접 다시 열심히 떨어져서 준비 해서 봤던 실망 탈락 경험 도...     E21       S06\n",
       "68      너무 이제 하고 있을까 면접 실패 취직 해서 결혼 한다는데 걱정 있다니 실망 스러워     E21       S06\n",
       "69          정말 회사 갈수록 새로 취업 실망 스러워 처음 좋았는데 별로 일이 사람 전체     E21       S06\n",
       "70    화가 같아 정말 회사 면접 만드는 좋지 떨어뜨린 물건 사지 않을 인재 알아본 나쁜 분명     E15       S06\n",
       "71                 같아 직장 여성 직원 이유 연봉 올려주지 않겠대 미혼 경우 심한     E15       S06\n",
       "72   직장 들어 대해 있어 노력 걱정 기간 감정 어릴 명확하게 가지 분야 진로 설정 해왔...     E15       S06\n",
       "73   같아 느껴져 회사 같은 기분 생길 따돌림 당하는 뭔가 업무 분담 악의 변호사 만나 ...     E15       S06\n",
       "74   너무 회사 취업 싶은 마음 빨리 발표 이렇게 나네 보고 좋겠어 모르겠어 하고 원서 ...     E16       S06\n",
       "75         싶어 취업 빨리 해서 가고 하고 싶다 벌고 월급 받으면 자동차 사고 여행 저축     E16       S06\n",
       "76            좋은 기다리고 면접 연락 없어서 좋겠어 있는데 결과 초조해 소식 있었으면     E16       S06\n",
       "77   회사 부모님 취업 해서 원하는 드디어 했어 그동안 죄송한 마음 들고 걱정 컸는데 한...     E67       S06\n",
       "78   같아 매일 업무 되나 괜히 했는데 해서 상사 그게 보고 하라 인제 와서 그러는 억울...     E47       S06\n",
       "79   회사 싶어 먼저 느껴져 좋은 다시 준비 해서 취업 친구 잊고 먹고 취직 했어 학교 ...     E54       S06\n",
       "80                        같아 취업 친구 우울해 준비 되어 진작 했는데 나서     E54       S06\n",
       "81                      정말 아직도 시험 대학 졸업 공무원 준비 붙지도 부족해     E26       S06\n",
       "82   면접 없어 좋겠어 없고 있으니 있었으면 이력서 여러 넣었지만 연락 오는 복도 없나 ...     E26       S06\n",
       "83   같아 회사 계속 없고 하게 요새 끝나고 오면 피곤해서 친구 보기 귀찮고 휴대전화 되...     E53       S06\n",
       "84   있지만 때문 코로나 갈수록 계속 준비 취업 하기 초조해 가뜩이나 어려운데 힘들어졌어...     E16       S06\n",
       "85   친한 해서 친구 있어 가장 사업 한다고 투자 했는데 파업 연락 없이 떠나 버렸어 법...     E42       S04\n",
       "86                                  받고 가족 맞나 생각 하더군 상처     E40       S04\n",
       "87      갑자기 열심히 취업 준비 간절한 마음 빠지네 하반기 좁아진다는 기사 보니 우울해지네     E24       S06\n",
       "88   화가 너무 하는 있지만 상사 달라 해서 참고 처리 동기 이상하게 먹어 지금 계속 되...     E15       S04\n",
       "89               때문 해야 해서 사람 됐어 하던 혼났는데 사과 어색한 사이 받아줄까     E51       S06\n",
       "90   너무 같아 그런 없어 능력 걱정 하고 보니 이러다가는 평생 연애 결혼 하는 드는 비...     E12       S05\n",
       "91   너무 나도 생각 갑자기 대해 있어 그동안 없이 결혼 친구 부끄러워하는 부끄럽네 아무...     E56       S05\n",
       "92   달라 취업 해서 생각 있는 있어 해야지 졸업 남았는데 캄캄해 전공 살릴 하면 좋겠다...     E24       S06\n",
       "93           같아 싶어 직업 해야 점점 보육 교사 힘들어지는 우울하네 보수 적고 힘들고     E24       S06\n",
       "94   나도 하는 아니야 엄마 모르겠어 있거든 위해 결혼 아내 매일 잔소리 사는 물건 작은...     E23       S05\n",
       "95   대한 생겨 걱정 결혼 준비 행복했는데 날짜 다가올수록 초조해지고 불안해져 막연한 두...     E30       S05\n",
       "96   자꾸 같아 않아 아직 있을 결혼 코앞 확신 들지 도망치려는 싫어져 여자친구 이야기 ...     E57       S05\n",
       "97     자꾸 너무 그런 달라 하는 결혼 생기 좋을 알았는데 없었어 들어가면 놀아 지쳐 한심해     E58       S05\n",
       "98        너무 하는데 근데 준비 결혼 하려고 친구 비교 되네 비슷한 시기 거든 과정 달라     E54       S05\n",
       "99   같아 질문 면접 오늘 준비 봤는데 네이버 인턴 봐도 나와서 대로 가진 장점 어필 있...     E69       S06\n",
       "100                          진짜 좋겠어 기뻐 결혼 낳았어 아내 건강했으면     E60       S05"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[51:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1e188687-fac2-4402-88cf-2b878a23958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv('data/250312_train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b613ffe0-8625-49fc-8b5c-4a9d6d43339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from konlpy.tag import Kkma\n",
    "\n",
    "# kkma = Kkma()\n",
    "\n",
    "# def preprocess_text_with_kkma(text):\n",
    "#     if not isinstance(text, str):  # NaN 처리\n",
    "#         return \"\"\n",
    "    \n",
    "#     # 형태소 분석\n",
    "#     parsed_text = kkma.pos(text)\n",
    "    \n",
    "#     keywords = []\n",
    "#     for word, tag in parsed_text:\n",
    "#         # 명사(NNG, NNP) 그대로 추가\n",
    "#         if tag in ['NNG', 'NNP']:\n",
    "#             keywords.append(word)\n",
    "        \n",
    "#         # 형용사(VA) 원형 변환 추가\n",
    "#         elif tag == 'VA':\n",
    "#             keywords.append(word)  # 'VA'형용사는 원형이 바로 해당 형태\n",
    "        \n",
    "#         # 동사(VV) 원형 변환 추가\n",
    "#         elif tag == 'VV':\n",
    "#             keywords.append(word)  # 'VV'형용사도 원형이 바로 해당 형태\n",
    "        \n",
    "#         # 부사(MAG) 추가\n",
    "#         elif tag == 'MAG':\n",
    "#             keywords.append(word)\n",
    "    \n",
    "#     # 중복 단어 제거 및 불용어 제거\n",
    "#     keywords = list(dict.fromkeys(keywords))  # 중복 제거\n",
    "#     keywords = [word for word in keywords if word not in korean_stopwords and len(word) > 1]  # 불용어 제거\n",
    "    \n",
    "#     return \" \".join(keywords)\n",
    "\n",
    "# train_df['text'] = train_df['text'].apply(preprocess_text_with_kkma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507d6678-0492-4f01-8477-4fb69db7af74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2374d28-2d85-4ec9-9a83-d0a35805086e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e926f8-b6e7-4c40-900c-4231b7a41420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "011d4d76-a532-43b1-b512-ccb964ac7ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^가-힣a-zA-Z0-9\\s]\", \"\", text)  # 한글, 영어, 숫자, 공백만 유지\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # 중복 공백 제거\n",
    "    return text\n",
    "\n",
    "train_df[\"text\"] = train_df[\"text\"].apply(clean_text)\n",
    "test_df[\"text\"] = test_df[\"text\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d3fa20b7-bbe4-47fa-9ea4-57f2b5690662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>situation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>없다 그냥 해결 부담</td>\n",
       "      <td>E18</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>급여 물가 월급 자꾸 너무 최대한 지출 억제 고정 없다</td>\n",
       "      <td>E18</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>회사 신입 말투 매일 생각 스트레스 사람 억지로 거리 예의</td>\n",
       "      <td>E18</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>직장 막내 이유 심부름 많다 정말 분하다 사람 이야기 방해</td>\n",
       "      <td>E18</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>입사 신입 사원 무시 너무 상사 먼저 인사 매일</td>\n",
       "      <td>E18</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               text emotion situation\n",
       "0                       없다 그냥 해결 부담     E18       S06\n",
       "1    급여 물가 월급 자꾸 너무 최대한 지출 억제 고정 없다     E18       S06\n",
       "2  회사 신입 말투 매일 생각 스트레스 사람 억지로 거리 예의     E18       S06\n",
       "3  직장 막내 이유 심부름 많다 정말 분하다 사람 이야기 방해     E18       S06\n",
       "4        입사 신입 사원 무시 너무 상사 먼저 인사 매일     E18       S06"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e987afa-9025-4ce8-8a95-57b4695ab525",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/250312_train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6583a56e-ed83-4570-9f15-752f7068aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 감정 라벨 인코딩\n",
    "emotion_encoder = LabelEncoder()\n",
    "train_df[\"emotion\"] = emotion_encoder.fit_transform(train_df[\"emotion\"])\n",
    "test_df[\"emotion\"] = emotion_encoder.transform(test_df[\"emotion\"])\n",
    "\n",
    "# 상황 라벨 인코딩\n",
    "situation_encoder = LabelEncoder()\n",
    "train_df[\"situation\"] = situation_encoder.fit_transform(train_df[\"situation\"])\n",
    "test_df[\"situation\"] = situation_encoder.transform(test_df[\"situation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbcdf34a-3fb5-42ad-b1e8-c1fd059ba66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>situation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>해도 없을까 화가 난다 그냥 해결 하는 나아 부담 주고 싶지도 않고</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>화가 급여 깎였어 물가 오르는데 월급 자꾸 깎이니까 너무 최대한 지출 억제 해야겠어...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>같아 회사 신입 들어왔는데 말투 거슬려 그런 매일 봐야 한다고 생각 하니까 스트레스...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>직장 막내 이유 온갖 심부름 시켜 일도 많은 정말 분하고 섭섭해 사람 솔직하게 이야...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>화가 너무 매일 입사 신입사원 나를 무시 하는 같아서 상사 먼저 인사 하지 않아서 한다고</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  emotion  \\\n",
       "0           0              해도 없을까 화가 난다 그냥 해결 하는 나아 부담 주고 싶지도 않고        8   \n",
       "1           1  화가 급여 깎였어 물가 오르는데 월급 자꾸 깎이니까 너무 최대한 지출 억제 해야겠어...        8   \n",
       "2           2  같아 회사 신입 들어왔는데 말투 거슬려 그런 매일 봐야 한다고 생각 하니까 스트레스...        8   \n",
       "3           3  직장 막내 이유 온갖 심부름 시켜 일도 많은 정말 분하고 섭섭해 사람 솔직하게 이야...        8   \n",
       "4           4  화가 너무 매일 입사 신입사원 나를 무시 하는 같아서 상사 먼저 인사 하지 않아서 한다고        8   \n",
       "\n",
       "   situation  \n",
       "0          5  \n",
       "1          5  \n",
       "2          5  \n",
       "3          5  \n",
       "4          5  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cec5b45a-5a3d-443d-ae26-322cf5db7519",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/250312_pre_train_df.csv', index_col=False)\n",
    "train_df.drop(columns=['Unnamed: 0'], inplace=True)\t\n",
    "train_df['word_count'] = train_df['text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "444944ba-6f24-4cd4-8735-be95c09549a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>situation</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>해도 없을까 화가 난다 그냥 해결 하는 나아 부담 주고 싶지도 않고</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>화가 급여 깎였어 물가 오르는데 월급 자꾸 깎이니까 너무 최대한 지출 억제 해야겠어...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>같아 회사 신입 들어왔는데 말투 거슬려 그런 매일 봐야 한다고 생각 하니까 스트레스...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>직장 막내 이유 온갖 심부름 시켜 일도 많은 정말 분하고 섭섭해 사람 솔직하게 이야...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>화가 너무 매일 입사 신입사원 나를 무시 하는 같아서 상사 먼저 인사 하지 않아서 한다고</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion  situation  \\\n",
       "0              해도 없을까 화가 난다 그냥 해결 하는 나아 부담 주고 싶지도 않고        8          5   \n",
       "1  화가 급여 깎였어 물가 오르는데 월급 자꾸 깎이니까 너무 최대한 지출 억제 해야겠어...        8          5   \n",
       "2  같아 회사 신입 들어왔는데 말투 거슬려 그런 매일 봐야 한다고 생각 하니까 스트레스...        8          5   \n",
       "3  직장 막내 이유 온갖 심부름 시켜 일도 많은 정말 분하고 섭섭해 사람 솔직하게 이야...        8          5   \n",
       "4  화가 너무 매일 입사 신입사원 나를 무시 하는 같아서 상사 먼저 인사 하지 않아서 한다고        8          5   \n",
       "\n",
       "   word_count  \n",
       "0          12  \n",
       "1          18  \n",
       "2          24  \n",
       "3          19  \n",
       "4          15  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "80dbdaf8-17c0-47e2-9caf-db9774313b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.108708434712085"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['word_count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6a1a332-3d32-4342-b2d1-b80bb9cbe139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 수가 10개 이하인 행 삭제\n",
    "train_df = train_df[train_df['word_count'] >= 30]\n",
    "# 'word_count' 컬럼 삭제 (필요 없으므로)\n",
    "train_df = train_df.drop(columns=['word_count'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73b48372-12e0-4568-9277-6b38ff9163af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 106696 entries, 144 to 197279\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   text       106696 non-null  object\n",
      " 1   emotion    106696 non-null  int64 \n",
      " 2   situation  106696 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9463ad6d-39be-4641-99ab-6e8e9b2ed1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f27276bf-5b0b-4bfd-96eb-b3df44990190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, AutoTokenizer\n",
    "\n",
    "# ✅ 1. KoBERT 커스텀 모델 정의 (감정 + 상황 다중 분류)\n",
    "class KoBERTMultiOutput(nn.Module):\n",
    "    def __init__(self, model_name, num_emotions, num_situations):\n",
    "        super(KoBERTMultiOutput, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)  # KoBERT 기본 모델\n",
    "        self.dropout = nn.Dropout(0.2)  # 드롭아웃 레이어 추가\n",
    "        self.emotion_classifier = nn.Linear(self.bert.config.hidden_size, num_emotions)  # 감정 분류기\n",
    "        self.situation_classifier = nn.Linear(self.bert.config.hidden_size, num_situations)  # 상황 분류기\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        # Bert 모델을 통해 출력값을 얻음\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = self.dropout(outputs.pooler_output)  # BERT 출력에서 pooling된 벡터에 드롭아웃 적용\n",
    "\n",
    "        # 감정과 상황을 위한 로짓 분리\n",
    "        emotion_logits = self.emotion_classifier(pooled_output)\n",
    "        situation_logits = self.situation_classifier(pooled_output)\n",
    "\n",
    "        # 두 가지 로짓 반환\n",
    "        return emotion_logits, situation_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5f9a8e4e-cd04-487a-85a0-042e7053c76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(len(train_df[\"emotion\"].unique()))\n",
    "print(len(train_df[\"situation\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26ceb93-c004-405c-90ba-6b22cbf9f354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kj\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1/20: 100%|███████████████████████████████████████| 6669/6669 [31:31<00:00,  3.53it/s, Loss=2.75, Accuracy=0.433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 1/20 - Loss: 4.4332 - Accuracy: 0.4330 - Time: 1891.28 sec\n",
      "✅ 모델이 개선되어 체크포인트 저장!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|███████████████████████████████████████| 6669/6669 [31:36<00:00,  3.52it/s, Loss=2.66, Accuracy=0.678]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 2/20 - Loss: 2.6484 - Accuracy: 0.6776 - Time: 1896.74 sec\n",
      "✅ 모델이 개선되어 체크포인트 저장!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|████████████████████████████████████████| 6669/6669 [31:09<00:00,  3.57it/s, Loss=2.1, Accuracy=0.793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 3/20 - Loss: 1.6668 - Accuracy: 0.7927 - Time: 1869.48 sec\n",
      "✅ 모델이 개선되어 체크포인트 저장!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████████████████████████████████| 6669/6669 [30:57<00:00,  3.59it/s, Loss=0.421, Accuracy=0.867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 4/20 - Loss: 1.0776 - Accuracy: 0.8673 - Time: 1857.22 sec\n",
      "✅ 모델이 개선되어 체크포인트 저장!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████████████████████████████████| 6669/6669 [30:57<00:00,  3.59it/s, Loss=0.385, Accuracy=0.917]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 5/20 - Loss: 0.6894 - Accuracy: 0.9171 - Time: 1857.53 sec\n",
      "✅ 모델이 개선되어 체크포인트 저장!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████████████████████████████████| 6669/6669 [30:58<00:00,  3.59it/s, Loss=0.138, Accuracy=0.947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 6/20 - Loss: 0.4459 - Accuracy: 0.9475 - Time: 1858.87 sec\n",
      "✅ 모델이 개선되어 체크포인트 저장!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|█████████████████████████████████████| 6669/6669 [30:59<00:00,  3.59it/s, Loss=0.0323, Accuracy=0.966]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 7/20 - Loss: 0.2948 - Accuracy: 0.9658 - Time: 1859.01 sec\n",
      "✅ 모델이 개선되어 체크포인트 저장!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|███████████████████████████████████████| 6669/6669 [30:58<00:00,  3.59it/s, Loss=0.29, Accuracy=0.977]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 8/20 - Loss: 0.2042 - Accuracy: 0.9771 - Time: 1858.78 sec\n",
      "✅ 모델이 개선되어 체크포인트 저장!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████████████████████████████████| 6669/6669 [30:59<00:00,  3.59it/s, Loss=0.514, Accuracy=0.984]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 9/20 - Loss: 0.1416 - Accuracy: 0.9844 - Time: 1859.72 sec\n",
      "✅ 모델이 개선되어 체크포인트 저장!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|███████████████████████████████████████| 6669/6669 [30:58<00:00,  3.59it/s, Loss=0.3, Accuracy=0.989]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 10/20 - Loss: 0.1034 - Accuracy: 0.9894 - Time: 1858.66 sec\n",
      "✅ 모델이 개선되어 체크포인트 저장!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|████████████████████████████████████| 6669/6669 [30:59<00:00,  3.59it/s, Loss=0.0495, Accuracy=0.992]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch 11/20 - Loss: 0.0787 - Accuracy: 0.9920 - Time: 1859.19 sec\n",
      "✅ 모델이 개선되어 체크포인트 저장!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20:  19%|███████▎                              | 1286/6669 [05:56<24:51,  3.61it/s, Loss=0.14, Accuracy=0.995]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW, get_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "from datetime import datetime\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ✅ 2. 모델 생성 (train_df의 감정, 상황 레이블 수에 맞춰 설정)\n",
    "num_emotions = len(train_df[\"emotion\"].unique())  # 감정 클래스 개수\n",
    "num_situations = len(train_df[\"situation\"].unique())  # 상황 클래스 개수\n",
    "model_name = \"monologg/kobert\"\n",
    "\n",
    "model = KoBERTMultiOutput(model_name, num_emotions, num_situations)  # 모델 초기화\n",
    "\n",
    "# ✅ 3. 디바이스 설정 (GPU 또는 CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "model.to(device)  # 모델을 설정한 디바이스로 이동\n",
    "\n",
    "# ✅ 4. 클래스 가중치 계산\n",
    "emotion_labels = train_df['emotion'].values\n",
    "situation_labels = train_df['situation'].values\n",
    "\n",
    "# 감정과 상황에 대한 클래스 가중치 계산\n",
    "emotion_class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(emotion_labels), y=emotion_labels)\n",
    "situation_class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(situation_labels), y=situation_labels)\n",
    "\n",
    "# 가중치를 텐서로 변환\n",
    "emotion_weights = torch.tensor(emotion_class_weights, dtype=torch.float).to(device)\n",
    "situation_weights = torch.tensor(situation_class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# ✅ 5. 손실 함수 설정 (가중치 적용)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=emotion_weights)  # 감정 클래스 가중치 적용\n",
    "situation_loss_fn = nn.CrossEntropyLoss(weight=situation_weights)  # 상황 클래스 가중치 적용\n",
    "\n",
    "# ✅ 6. 옵티마이저 및 학습률 스케줄러 설정\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)  # AdamW 옵티마이저 사용\n",
    "num_training_steps = len(train_dataloader) * 20  # 학습할 총 스텝 수 \n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)  # 학습률 스케줄러 설정\n",
    "\n",
    "# ✅ 7. 모델 학습\n",
    "num_epochs = 20\n",
    "train_accuracy_history = []  # 정확도 기록\n",
    "train_loss_history = []  # 손실값 기록\n",
    "\n",
    "# 얼리스탑을 위한 변수 초기화\n",
    "best_accuracy = 0.0  # 가장 좋은 정확도\n",
    "patience = 5  # 개선되지 않아도 허용할 에포크 수\n",
    "early_stopping_counter = 0  # 얼리스탑 카운터\n",
    "\n",
    "# 모델 체크포인트 저장을 위한 경로 설정\n",
    "model_path = \"kobert_emotion_situation\"\n",
    "os.makedirs(model_path, exist_ok=True)  # 디렉토리가 없으면 생성\n",
    "\n",
    "\n",
    "# ✅ 8. 학습 시작\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 모델을 학습 모드로 설정\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    epoch_accuracy = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        # 배치 데이터를 디바이스로 이동\n",
    "        input_ids, attention_mask, token_type_ids, emotion_labels, situation_labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        token_type_ids = token_type_ids.to(device)\n",
    "        emotion_labels = emotion_labels.to(device)\n",
    "        situation_labels = situation_labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        emotion_logits, situation_logits = model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "        # 손실 계산 (가중치 적용)\n",
    "        emotion_loss = loss_fn(emotion_logits, emotion_labels)\n",
    "        situation_loss = situation_loss_fn(situation_logits, situation_labels)\n",
    "\n",
    "        loss = emotion_loss + situation_loss\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()  # 기울기 초기화\n",
    "        loss.backward()  # 기울기 계산\n",
    "        optimizer.step()  # 최적화\n",
    "        lr_scheduler.step()  # 학습률 스케줄러 업데이트\n",
    "\n",
    "        total_loss += loss.item()  # 손실값 누적\n",
    "\n",
    "        # 정확도 계산\n",
    "        emotion_pred = torch.argmax(emotion_logits, dim=1)\n",
    "        situation_pred = torch.argmax(situation_logits, dim=1)\n",
    "\n",
    "        correct += (emotion_pred == emotion_labels).sum().item()\n",
    "        correct += (situation_pred == situation_labels).sum().item()\n",
    "        total += emotion_labels.size(0) + situation_labels.size(0)\n",
    "\n",
    "        # 정확도 업데이트\n",
    "        epoch_accuracy = correct / total\n",
    "\n",
    "        # 진행상황을 바에 손실값과 정확도 표시\n",
    "        progress_bar.set_postfix({\"Loss\": loss.item(), \"Accuracy\": epoch_accuracy})\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)  # 평균 손실 계산\n",
    "    epoch_accuracy = correct / total  # 에포크별 정확도 계산\n",
    "\n",
    "    # 에포크별 손실과 정확도 기록\n",
    "    train_loss_history.append(avg_loss)\n",
    "    train_accuracy_history.append(epoch_accuracy)\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"✅ Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f} - Accuracy: {epoch_accuracy:.4f} - Time: {epoch_time:.2f} sec\")\n",
    "\n",
    "    # 얼리스탑 조건: 성능이 개선되지 않으면 학습을 중지\n",
    "    if epoch_accuracy > best_accuracy:\n",
    "        best_accuracy = epoch_accuracy\n",
    "        early_stopping_counter = 0\n",
    "        # 현재 모델을 체크포인트로 저장\n",
    "        torch.save(model.state_dict(), f\"{model_path}/best_model.pth\")\n",
    "        print(\"✅ 모델이 개선되어 체크포인트 저장!\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        print(f\"❌ 모델 성능이 개선되지 않았습니다. (이미 개선된 횟수: {early_stopping_counter})\")\n",
    "\n",
    "    # 얼리스탑 발동 여부 확인\n",
    "    if early_stopping_counter >= patience:\n",
    "        print(f\"⚠️ 얼리스탑 발동! 성능이 개선되지 않았습니다. (최대 {patience} 에포크)\")\n",
    "        break  # 학습 중지\n",
    "\n",
    "print(\"🎉 KoBERT 학습 완료!\")\n",
    "\n",
    "# ✅ 모델 저장 (최종 모델 가중치 및 학습 기록 포함)\n",
    "torch.save(model.state_dict(), f\"{model_path}/final_model.pth\")  # 최종 모델 저장\n",
    "torch.save({'train_loss': train_loss_history, 'train_accuracy': train_accuracy_history}, f\"{model_path}/history.pth\")  # 학습 기록\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b069d9d-7e06-478a-81cb-16136c729228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15896cc2-2187-45bd-9ad2-232a01e69641",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# 정확도 시각화\u001b[39;00m\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), train_accuracy_history, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Accuracy per Epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_epochs' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ✅ 학습 기록 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# 정확도 시각화\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_epochs+1), train_accuracy_history, marker='o', color='b', label=\"Train Accuracy\")\n",
    "plt.title(\"Train Accuracy per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "\n",
    "# 손실 시각화\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_epochs+1), train_loss_history, marker='x', color='r', label=\"Train Loss\")\n",
    "plt.title(\"Train Loss per Epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3313b1cd-1ee9-47bd-a9a2-e089ea3db101",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'E31'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m test_texts \u001b[38;5;241m=\u001b[39m test_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()  \u001b[38;5;66;03m# 'text' 컬럼에 테스트 데이터가 있다고 가정\u001b[39;00m\n\u001b[0;32m     31\u001b[0m test_encodings \u001b[38;5;241m=\u001b[39m tokenizer(test_texts, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m emotion_labels_test \u001b[38;5;241m=\u001b[39m emotion_encoder\u001b[38;5;241m.\u001b[39mtransform(test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)  \u001b[38;5;66;03m# 감정 라벨\u001b[39;00m\n\u001b[0;32m     34\u001b[0m situation_labels_test \u001b[38;5;241m=\u001b[39m situation_encoder\u001b[38;5;241m.\u001b[39mtransform(test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msituation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)  \u001b[38;5;66;03m# 상황 라벨\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# 텐서로 변환\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:132\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform labels to normalized encoding.\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m    Labels as normalized encodings.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 132\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mdtype, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;66;03m# transform of empty array is empty array\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1381\u001b[0m, in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, dtype, warn)\u001b[0m\n\u001b[0;32m   1349\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Ravel column or 1d numpy array, else raises an error.\u001b[39;00m\n\u001b[0;32m   1350\u001b[0m \n\u001b[0;32m   1351\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1378\u001b[0m \u001b[38;5;124;03marray([1, 1])\u001b[39;00m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1380\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y)\n\u001b[1;32m-> 1381\u001b[0m y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1382\u001b[0m     y,\n\u001b[0;32m   1383\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1384\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1385\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1386\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1387\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   1388\u001b[0m )\n\u001b[0;32m   1390\u001b[0m shape \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1010\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39misdtype(array\u001b[38;5;241m.\u001b[39mdtype, (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreal floating\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplex floating\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m   1003\u001b[0m         _assert_all_finite(\n\u001b[0;32m   1004\u001b[0m             array,\n\u001b[0;32m   1005\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1008\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[0;32m   1009\u001b[0m         )\n\u001b[1;32m-> 1010\u001b[0m     array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1012\u001b[0m     array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:390\u001b[0m, in \u001b[0;36m_NumPyAPIWrapper.astype\u001b[1;34m(self, x, dtype, copy, casting)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mastype\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, dtype, \u001b[38;5;241m*\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;66;03m# astype is not defined in the top level NumPy namespace\u001b[39;00m\n\u001b[1;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, casting\u001b[38;5;241m=\u001b[39mcasting)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'E31'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, AutoTokenizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ✅ 2. 감정과 상황의 클래스 수 계산\n",
    "num_emotions = len(train_df[\"emotion\"].unique())  # 감정 클래스 개수\n",
    "num_situations = len(train_df[\"situation\"].unique())  # 상황 클래스 개수\n",
    "\n",
    "# ✅ 3. 모델 초기화\n",
    "model_name = \"monologg/kobert\"  # KoBERT 모델명\n",
    "model = KoBERTMultiOutput(model_name, num_emotions, num_situations)  # num_emotions, num_situations 정의 완료\n",
    "\n",
    "# ✅ 4. device 설정 (GPU/CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # CUDA (GPU) 사용 가능 여부 확인\n",
    "model.to(device)  # 모델을 해당 device로 이동\n",
    "\n",
    "# 모델 체크포인트 불러오기\n",
    "model.load_state_dict(torch.load(\"kobert_emotion_situation/250312_best_model.pth\"))\n",
    "model.to(device)  # 다시 device로 모델 이동\n",
    "\n",
    "# ✅ 5. 학습 기록 불러오기\n",
    "history = torch.load(\"kobert_emotion_situation/250312_history.pth\", weights_only=True)\n",
    "train_loss_history = history['train_loss']\n",
    "train_accuracy_history = history['train_accuracy']\n",
    "\n",
    "# ✅ 6. 테스트 데이터셋 준비 (test_dataloader)\n",
    "test_texts = test_df[\"text\"].tolist()  # 'text' 컬럼에 테스트 데이터가 있다고 가정\n",
    "test_encodings = tokenizer(test_texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "emotion_labels_test = emotion_encoder.transform(test_df['emotion'].values)  # 감정 라벨\n",
    "situation_labels_test = situation_encoder.transform(test_df['situation'].values)  # 상황 라벨\n",
    "\n",
    "# 텐서로 변환\n",
    "emotion_labels_test = torch.tensor(emotion_labels_test)\n",
    "situation_labels_test = torch.tensor(situation_labels_test)\n",
    "\n",
    "# Test Dataset과 DataLoader 생성\n",
    "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_encodings['token_type_ids'],\n",
    "                             emotion_labels_test, situation_labels_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "# ✅ 7. 모델 평가 함수 (F1-Score와 Exact Match 추가)\n",
    "def evaluate_model(model, test_dataloader, loss_fn, device, emotion_encoder, situation_encoder):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_emotion_preds = []\n",
    "    all_situation_preds = []\n",
    "    all_emotion_labels = []\n",
    "    all_situation_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            input_ids, attention_mask, token_type_ids, emotion_labels, situation_labels = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "            emotion_labels = emotion_labels.to(device)\n",
    "            situation_labels = situation_labels.to(device)\n",
    "\n",
    "            emotion_logits, situation_logits = model(input_ids, attention_mask, token_type_ids)\n",
    "            loss = loss_fn(emotion_logits, emotion_labels) + loss_fn(situation_logits, situation_labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            emotion_pred = torch.argmax(emotion_logits, dim=1)\n",
    "            situation_pred = torch.argmax(situation_logits, dim=1)\n",
    "\n",
    "            correct += (emotion_pred == emotion_labels).sum().item()\n",
    "            correct += (situation_pred == situation_labels).sum().item()\n",
    "            total += emotion_labels.size(0) + situation_labels.size(0)\n",
    "\n",
    "            all_emotion_preds.extend(emotion_pred.cpu().numpy())\n",
    "            all_situation_preds.extend(situation_pred.cpu().numpy())\n",
    "            all_emotion_labels.extend(emotion_labels.cpu().numpy())\n",
    "            all_situation_labels.extend(situation_labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(test_dataloader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    # 감정과 상황에 대해 F1-Score 계산\n",
    "    emotion_f1 = f1_score(all_emotion_labels, all_emotion_preds, average='weighted')\n",
    "    situation_f1 = f1_score(all_situation_labels, all_situation_preds, average='weighted')\n",
    "\n",
    "    # Exact Match 계산 (True는 1.0, False는 0.0으로 변환)\n",
    "    # 예측값을 디코딩하여 정확히 일치하는지 확인\n",
    "    emotion_exact_match = (emotion_encoder.inverse_transform(all_emotion_labels) == emotion_encoder.inverse_transform(all_emotion_preds)).mean()\n",
    "    situation_exact_match = (situation_encoder.inverse_transform(all_situation_labels) == situation_encoder.inverse_transform(all_situation_preds)).mean()\n",
    "\n",
    "    # 감정 정확도, 상황 정확도 계산\n",
    "    emotion_accuracy = accuracy_score(all_emotion_labels, all_emotion_preds)\n",
    "    situation_accuracy = accuracy_score(all_situation_labels, all_situation_preds)\n",
    "\n",
    "    return avg_loss, accuracy, emotion_accuracy, situation_accuracy, emotion_f1, situation_f1, emotion_exact_match, situation_exact_match\n",
    "\n",
    "\n",
    "\n",
    "# ✅ 8. 손실 함수 정의\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# ✅ 9. 모델 평가 실행\n",
    "test_loss, test_accuracy, emotion_accuracy, situation_accuracy, emotion_f1, situation_f1, emotion_exact_match, situation_exact_match = evaluate_model(\n",
    "    model, test_dataloader, loss_fn, device, emotion_encoder, situation_encoder\n",
    ")\n",
    "\n",
    "\n",
    "# ✅ 10. 결과 출력\n",
    "print(f\"✅ Test Loss: {test_loss:.4f}\")\n",
    "print(f\"✅ Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"✅ Emotion Accuracy: {emotion_accuracy:.4f}\")\n",
    "print(f\"✅ Situation Accuracy: {situation_accuracy:.4f}\")\n",
    "print(f\"✅ Emotion F1-Score: {emotion_f1:.4f}\")\n",
    "print(f\"✅ Situation F1-Score: {situation_f1:.4f}\")\n",
    "print(f\"✅ Emotion Exact Match: {emotion_exact_match:.4f}\")\n",
    "print(f\"✅ Situation Exact Match: {situation_exact_match:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74400c02-0373-4474-91bc-e45eb1052b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3641d5ae-5fe8-4ca1-804e-e02824bd5287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cff423e-8314-4cee-adf0-58da7c69faae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b70fec-3b0f-4ecf-aafe-43743d1c6fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd568741-b08a-4036-a500-962e607d70bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
