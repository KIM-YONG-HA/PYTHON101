{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc6b606a-fca7-4bc5-9f05-413fe33b39a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ì €ì¥ëœ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "final_df = pd.read_csv('data/final_df_preprocessed.csv', encoding='utf-8-sig')\n",
    "test_df = pd.read_csv('data/test_df_preprocessed.csv', encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e21ee9d0-9f39-4ca3-8c85-55ca3657de37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  persona-id  emotion-id  \\\n",
      "0              í•´ë„ ì—†ì„ê¹Œ í™”ê°€ ë‚œë‹¤ ê·¸ëƒ¥ í•´ê²° í•˜ëŠ” ë‚˜ì•„ ë¶€ë‹´ ì£¼ê³  ì‹¶ì§€ë„ ì•Šê³            3         368   \n",
      "1  ê¸‰ì—¬ ê¹ì˜€ì–´ ë¬¼ê°€ ì˜¤ë¥´ëŠ”ë° ì›”ê¸‰ ìê¾¸ ê¹ì´ë‹ˆê¹Œ ë„ˆë¬´ í™”ê°€ ìµœëŒ€í•œ ì§€ì¶œ ì–µì œ í•´ì•¼ê² ì–´...           3         368   \n",
      "2  íšŒì‚¬ ì‹ ì… ë“¤ì–´ì™”ëŠ”ë° ë§íˆ¬ ê±°ìŠ¬ë ¤ ê·¸ëŸ° ë§¤ì¼ ë´ì•¼ í•œë‹¤ê³  ìƒê° í•˜ë‹ˆê¹Œ ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•„...           3         368   \n",
      "3  ì§ì¥ ë§‰ë‚´ ì´ìœ  ì˜¨ê°– ì‹¬ë¶€ë¦„ ì‹œì¼œ ì¼ë„ ë§ì€ ì •ë§ ë¶„í•˜ê³  ì„­ì„­í•´ ì‚¬ëŒ ì†”ì§í•˜ê²Œ ì´ì•¼...           3         368   \n",
      "4  ì…ì‚¬ ì‹ ì…ì‚¬ì› ë‚˜ë¥¼ ë¬´ì‹œ í•˜ëŠ” ê°™ì•„ì„œ ë„ˆë¬´ í™”ê°€ ìƒì‚¬ ë¨¼ì € ì¸ì‚¬ í•˜ì§€ ì•Šì•„ì„œ ë§¤ì¼ í•œë‹¤ê³            3         368   \n",
      "\n",
      "   emotion  situation  disease  text_pca_1  text_pca_2  \n",
      "0        8          5        1   -0.045439    0.059560  \n",
      "1        8          5        1    0.036776    0.019723  \n",
      "2        8          5        1   -0.196787    0.278481  \n",
      "3        8          5        1   -0.082461    0.201029  \n",
      "4        8          5        1    0.063519    0.064646  \n",
      "                                                text  persona-id  emotion-id  \\\n",
      "0  ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„œ ë°œí‘œë¥¼ í•˜ëŠ”ë° ë‚´ê°€ ì‹¤ìˆ˜í•˜ëŠ” ë°”ëŒì— ìš°ë¦¬ íŒ€ì´ ê°ì ì„ ë°›ì•˜ì–´ ë„ˆë¬´...           2         381   \n",
      "1  íšŒì‚¬ì—ì„œ ì¤‘ìš”í•œ í”„ë¡œì íŠ¸ë¥¼ í˜¼ì í•˜ê²Œ ëëŠ”ë° ì†”ì§íˆ ë‘ë µê³  ë¬´ì„œì›Œ ë‚˜ì—ê²Œ ë„ˆë¬´ í¬ê²Œ...           2         381   \n",
      "2  ìƒì‚¬ê°€ ë„ˆë¬´ ë¬´ì„­ê²Œ ìƒê²¨ì„œ ì¹œí•´ì§€ëŠ” ê²Œ ë„ˆë¬´ ë‘ë ¤ì›Œ ë¬´ì„­ê²Œ ìƒê²¼ëŠ”ë°ë„ ì—…ë¬´ë¥¼ ë³´ë ¤ë©´...           2         381   \n",
      "3  ì´ë²ˆì— í˜ë“¤ê²Œ ë“¤ì–´ê°„ ì²« ì§ì¥ì´ê±°ë“  ì²« ì§ì¥ì´ë¼ì„œ ê·¸ëŸ°ì§€ ë„ˆë¬´ ê¸´ì¥ëœë‹¤ ì²« ì§ì¥ì´ì–´...           2         381   \n",
      "4  ì§ì¥ì—ì„œ ë™ë£Œë“¤ì´ë‘ ê´€ê³„ê°€ ì•ˆ ì¢‹ì•„ì§ˆê¹Œ ë´ ê±±ì •ë¼ ë‚´ê°€ ë‚¯ê°€ë¦¼ì´ ì‹¬í•´ì„œ ì¹œí•´ì§ˆ ìˆ˜ ...           2         381   \n",
      "\n",
      "   emotion  situation  disease  text_pca_1  text_pca_2  \n",
      "0       21          5        1   -0.001888   -0.313635  \n",
      "1       21          5        1    0.011658   -0.092545  \n",
      "2       21          5        1    0.147893   -0.197571  \n",
      "3       21          5        1   -0.006208   -0.136605  \n",
      "4       21          5        1   -0.133726    0.267530  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a00eaec0-cb85-437f-baa8-13abc987fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ê°ì • ë¼ë²¨ ì¸ì½”ë”©\n",
    "emotion_encoder = LabelEncoder()\n",
    "final_df[\"emotion\"] = emotion_encoder.fit_transform(final_df[\"emotion\"])\n",
    "test_df[\"emotion\"] = emotion_encoder.transform(test_df[\"emotion\"])\n",
    "\n",
    "# ìƒí™© ë¼ë²¨ ì¸ì½”ë”©\n",
    "situation_encoder = LabelEncoder()\n",
    "final_df[\"situation\"] = situation_encoder.fit_transform(final_df[\"situation\"])\n",
    "test_df[\"situation\"] = situation_encoder.transform(test_df[\"situation\"])\n",
    "\n",
    "# ì§ˆë³‘ ë¼ë²¨ ì¸ì½”ë”©\n",
    "disease_encoder = LabelEncoder()\n",
    "final_df[\"disease\"] = disease_encoder.fit_transform(final_df[\"disease\"])\n",
    "test_df[\"disease\"] = disease_encoder.transform(test_df[\"disease\"])\n",
    "\n",
    "# ë ˆì´ë¸” ì¸ì½”ë”©: persona-id, emotion-id ìˆ«ìë¡œ ë³€í™˜\n",
    "persona_encoder = LabelEncoder()\n",
    "final_df['persona-id'] = persona_encoder.fit_transform(final_df['persona-id'])\n",
    "test_df['persona-id'] = persona_encoder.transform(test_df['persona-id'])\n",
    "\n",
    "emotionid_encoder = LabelEncoder()\n",
    "final_df['emotion-id'] = emotionid_encoder.fit_transform(final_df['emotion-id'])\n",
    "test_df['emotion-id'] = emotionid_encoder.transform(test_df['emotion-id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e2e5265-f328-4797-b3fe-30e334ef6c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  persona-id  emotion-id  \\\n",
      "0              í•´ë„ ì—†ì„ê¹Œ í™”ê°€ ë‚œë‹¤ ê·¸ëƒ¥ í•´ê²° í•˜ëŠ” ë‚˜ì•„ ë¶€ë‹´ ì£¼ê³  ì‹¶ì§€ë„ ì•Šê³            3         368   \n",
      "1  ê¸‰ì—¬ ê¹ì˜€ì–´ ë¬¼ê°€ ì˜¤ë¥´ëŠ”ë° ì›”ê¸‰ ìê¾¸ ê¹ì´ë‹ˆê¹Œ ë„ˆë¬´ í™”ê°€ ìµœëŒ€í•œ ì§€ì¶œ ì–µì œ í•´ì•¼ê² ì–´...           3         368   \n",
      "2  íšŒì‚¬ ì‹ ì… ë“¤ì–´ì™”ëŠ”ë° ë§íˆ¬ ê±°ìŠ¬ë ¤ ê·¸ëŸ° ë§¤ì¼ ë´ì•¼ í•œë‹¤ê³  ìƒê° í•˜ë‹ˆê¹Œ ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•„...           3         368   \n",
      "3  ì§ì¥ ë§‰ë‚´ ì´ìœ  ì˜¨ê°– ì‹¬ë¶€ë¦„ ì‹œì¼œ ì¼ë„ ë§ì€ ì •ë§ ë¶„í•˜ê³  ì„­ì„­í•´ ì‚¬ëŒ ì†”ì§í•˜ê²Œ ì´ì•¼...           3         368   \n",
      "4  ì…ì‚¬ ì‹ ì…ì‚¬ì› ë‚˜ë¥¼ ë¬´ì‹œ í•˜ëŠ” ê°™ì•„ì„œ ë„ˆë¬´ í™”ê°€ ìƒì‚¬ ë¨¼ì € ì¸ì‚¬ í•˜ì§€ ì•Šì•„ì„œ ë§¤ì¼ í•œë‹¤ê³            3         368   \n",
      "\n",
      "   emotion  situation  disease  text_pca_1  text_pca_2  \n",
      "0        8          5        1   -0.045439    0.059560  \n",
      "1        8          5        1    0.036776    0.019723  \n",
      "2        8          5        1   -0.196787    0.278481  \n",
      "3        8          5        1   -0.082461    0.201029  \n",
      "4        8          5        1    0.063519    0.064646  \n",
      "                                                text  persona-id  emotion-id  \\\n",
      "0  ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„œ ë°œí‘œë¥¼ í•˜ëŠ”ë° ë‚´ê°€ ì‹¤ìˆ˜í•˜ëŠ” ë°”ëŒì— ìš°ë¦¬ íŒ€ì´ ê°ì ì„ ë°›ì•˜ì–´ ë„ˆë¬´...           2         381   \n",
      "1  íšŒì‚¬ì—ì„œ ì¤‘ìš”í•œ í”„ë¡œì íŠ¸ë¥¼ í˜¼ì í•˜ê²Œ ëëŠ”ë° ì†”ì§íˆ ë‘ë µê³  ë¬´ì„œì›Œ ë‚˜ì—ê²Œ ë„ˆë¬´ í¬ê²Œ...           2         381   \n",
      "2  ìƒì‚¬ê°€ ë„ˆë¬´ ë¬´ì„­ê²Œ ìƒê²¨ì„œ ì¹œí•´ì§€ëŠ” ê²Œ ë„ˆë¬´ ë‘ë ¤ì›Œ ë¬´ì„­ê²Œ ìƒê²¼ëŠ”ë°ë„ ì—…ë¬´ë¥¼ ë³´ë ¤ë©´...           2         381   \n",
      "3  ì´ë²ˆì— í˜ë“¤ê²Œ ë“¤ì–´ê°„ ì²« ì§ì¥ì´ê±°ë“  ì²« ì§ì¥ì´ë¼ì„œ ê·¸ëŸ°ì§€ ë„ˆë¬´ ê¸´ì¥ëœë‹¤ ì²« ì§ì¥ì´ì–´...           2         381   \n",
      "4  ì§ì¥ì—ì„œ ë™ë£Œë“¤ì´ë‘ ê´€ê³„ê°€ ì•ˆ ì¢‹ì•„ì§ˆê¹Œ ë´ ê±±ì •ë¼ ë‚´ê°€ ë‚¯ê°€ë¦¼ì´ ì‹¬í•´ì„œ ì¹œí•´ì§ˆ ìˆ˜ ...           2         381   \n",
      "\n",
      "   emotion  situation  disease  text_pca_1  text_pca_2  \n",
      "0       21          5        1   -0.001888   -0.313635  \n",
      "1       21          5        1    0.011658   -0.092545  \n",
      "2       21          5        1    0.147893   -0.197571  \n",
      "3       21          5        1   -0.006208   -0.136605  \n",
      "4       21          5        1   -0.133726    0.267530  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "120f4c93-6ce8-423c-9e03-84961f20aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ğŸ”¹ Step 1: í…ìŠ¤íŠ¸ ë°ì´í„° ë²¡í„°í™” (TF-IDF)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=100)  # ìµœëŒ€ 100ê°œ íŠ¹ì„± ì¶”ì¶œ\n",
    "\n",
    "# final_dfì—ì„œ TF-IDF ë²¡í„°í™”\n",
    "tfidf_matrix_train = tfidf_vectorizer.fit_transform(final_df['text'])\n",
    "\n",
    "# test_dfì—ì„œ TF-IDF ë²¡í„°í™” (í•™ìŠµëœ vectorizer ì‚¬ìš©)\n",
    "tfidf_matrix_test = tfidf_vectorizer.transform(test_df['text'])\n",
    "\n",
    "# ğŸ”¹ Step 2: í…ìŠ¤íŠ¸ ë°ì´í„° ì°¨ì› ì¶•ì†Œ (PCA)\n",
    "pca = PCA(n_components=2)  # 2Dë¡œ ì¶•ì†Œ\n",
    "\n",
    "# final_dfì—ì„œ PCA ì ìš©\n",
    "text_pca_train = pca.fit_transform(tfidf_matrix_train.toarray())\n",
    "\n",
    "# test_dfì—ì„œ PCA ì ìš© (í•™ìŠµëœ PCA ëª¨ë¸ ì‚¬ìš©)\n",
    "text_pca_test = pca.transform(tfidf_matrix_test.toarray())\n",
    "\n",
    "# ğŸ”¹ Step 3: í…ìŠ¤íŠ¸ ë²¡í„°í™”ëœ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€\n",
    "final_df['text_pca_1'] = text_pca_train[:, 0]\n",
    "final_df['text_pca_2'] = text_pca_train[:, 1]\n",
    "\n",
    "test_df['text_pca_1'] = text_pca_test[:, 0]\n",
    "test_df['text_pca_2'] = text_pca_test[:, 1]\n",
    "\n",
    "# ğŸ”¹ Step 4: ìƒê´€ í–‰ë ¬ ê³„ì‚°\n",
    "# ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì— ëŒ€í•´ì„œë§Œ ìƒê´€ ê´€ê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "correlation_matrix_train = final_df[['text_pca_1', 'text_pca_2', 'emotion', 'situation', 'persona-id', 'emotion-id']].apply(pd.to_numeric, errors='coerce').corr()\n",
    "\n",
    "# # ğŸ”¹ Step 5: ìƒê´€ í–‰ë ¬ ì‹œê°í™” (final_df)\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(correlation_matrix_train, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "# plt.title('Correlation Matrix: Text, Persona-id, Emotion-id, Emotion, Situation (Train Data)')\n",
    "# plt.show()\n",
    "\n",
    "# # ğŸ”¹ Step 6: ìƒí™©ì— ë”°ë¥¸ ê°ì • ë¶„í¬ (final_df)\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.countplot(data=final_df, x='situation', hue='emotion', palette='Set2')\n",
    "# plt.title('Emotion Distribution per Situation (Train Data)')\n",
    "# plt.xlabel('Situation')\n",
    "# plt.ylabel('Count')\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.legend(title='Emotion')\n",
    "# plt.show()\n",
    "\n",
    "# # ğŸ”¹ Step 7: í˜ë¥´ì†Œë‚˜ ì•„ì´ë””ì™€ ê°ì • ì•„ì´ë””ì— ë”°ë¥¸ ê°ì • ë¶„í¬ (final_df)\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.countplot(data=final_df, x='persona-id', hue='emotion', palette='Set1')\n",
    "# plt.title('Emotion Distribution by Persona-id (Train Data)')\n",
    "# plt.xlabel('Persona-id')\n",
    "# plt.ylabel('Count')\n",
    "# plt.legend(title='Emotion')\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cb762c-962d-4ac0-8d85-265c16cdec6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636db661-7745-4661-9af9-3f829be76f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d20ef82-5d5b-4fc0-bc6e-c137556264ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCustomDataset\u001b[39;00m(Dataset):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataframe, tokenizer, max_len, pca_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataframe \u001b[38;5;241m=\u001b[39m dataframe\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len, pca_features=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.pca_features = pca_features  # PCA íŠ¹ì„± (ì„ íƒ ì‚¬í•­)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.dataframe.iloc[index]['text']\n",
    "        emotion = self.dataframe.iloc[index]['emotion']\n",
    "        situation = self.dataframe.iloc[index]['situation']\n",
    "        persona_id = self.dataframe.iloc[index]['persona-id']\n",
    "        emotion_id = self.dataframe.iloc[index]['emotion-id']\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids = encoding['input_ids'].squeeze(0)  # (1, seq_len) -> (seq_len,)\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)  # (1, seq_len) -> (seq_len,)\n",
    "        token_type_ids = encoding['token_type_ids'].squeeze(0) if 'token_type_ids' in encoding else torch.zeros_like(input_ids)\n",
    "\n",
    "        # pca_featuresë¥¼ í¬í•¨í•˜ë„ë¡ ìˆ˜ì •\n",
    "        pca_feature = self.pca_features[index] if self.pca_features is not None else torch.zeros(2)  # 2D PCA íŠ¹ì„± ì˜ˆì‹œ (í•„ìš”í•œ íŠ¹ì„±ì— ë§ê²Œ ìˆ˜ì •)\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'token_type_ids': token_type_ids,\n",
    "            'emotion': torch.tensor(emotion, dtype=torch.long),\n",
    "            'situation': torch.tensor(situation, dtype=torch.long),\n",
    "            'persona-id': torch.tensor(persona_id, dtype=torch.long),\n",
    "            'emotion-id': torch.tensor(emotion_id, dtype=torch.long),\n",
    "            'pca_features': pca_feature  # pca_features ì¶”ê°€\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f311c829-0d1b-40b1-b6f4-bc699ed170ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA ì ìš© (ì˜ˆì‹œ)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=100)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(final_df['text'])\n",
    "\n",
    "# PCA ì ìš© (2Dë¡œ ì¶•ì†Œ)\n",
    "pca = PCA(n_components=2)\n",
    "pca_features_train = pca.fit_transform(tfidf_matrix.toarray())\n",
    "\n",
    "# ë°ì´í„°ì…‹ì— PCA íŠ¹ì„± ì¶”ê°€\n",
    "train_dataset = CustomDataset(final_df, tokenizer, max_len=128, pca_features=pca_features_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# PCA íŠ¹ì„±ì„ test ë°ì´í„°ì—ë„ ì ìš©\n",
    "tfidf_matrix_test = tfidf_vectorizer.transform(test_df['text'])\n",
    "pca_features_test = pca.transform(tfidf_matrix_test.toarray())\n",
    "\n",
    "test_dataset = CustomDataset(test_df, tokenizer, max_len=128, pca_features=pca_features_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d2f4c4-166b-4abc-a801-e46e0bb6c6d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a80b6e81-59bf-4dbd-96b4-8deebe58dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class KoBERTMultiOutputWithEmbedding(nn.Module):\n",
    "    def __init__(self, model_name, num_emotions, num_situations, num_personas, num_emotion_ids, embedding_dim=10):\n",
    "        super(KoBERTMultiOutputWithEmbedding, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)  # KoBERT ê¸°ë³¸ ëª¨ë¸\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # ê°ì • ë¶„ë¥˜ ë ˆì´ì–´ (ì…ë ¥ í¬ê¸° í™•ì¸)\n",
    "        self.emotion_classifier = nn.Linear(768 + 2 * embedding_dim, num_emotions)  # BERT ì¶œë ¥ + ì„ë² ë”© ì°¨ì› í¬ê¸°\n",
    "        self.situation_classifier = nn.Linear(768, num_situations)  # ìƒí™© ì˜ˆì¸¡ì€ BERTë§Œ ì‚¬ìš©\n",
    "\n",
    "        # persona-idì™€ emotion-idë¥¼ ìœ„í•œ ì„ë² ë”© ë ˆì´ì–´\n",
    "        self.persona_embedding = nn.Embedding(num_personas, embedding_dim)  # persona-id ì„ë² ë”©\n",
    "        self.emotion_id_embedding = nn.Embedding(num_emotion_ids, embedding_dim)  # emotion-id ì„ë² ë”©\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, persona_id, emotion_id, pca_features):\n",
    "        # BERT ëª¨ë¸ì—ì„œ ì¶œë ¥ê°’ ì–»ê¸°\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs.pooler_output  # (batch_size, 768)\n",
    "\n",
    "        # persona-idì™€ emotion-id ì„ë² ë”©\n",
    "        persona_embedding = self.persona_embedding(persona_id)  # (batch_size, embedding_dim)\n",
    "        emotion_id_embedding = self.emotion_id_embedding(emotion_id)  # (batch_size, embedding_dim)\n",
    "\n",
    "        # ì„ë² ë”© ë²¡í„°ë¥¼ BERT ì¶œë ¥ê³¼ ê²°í•©\n",
    "        combined_output = torch.cat((pooled_output, persona_embedding, emotion_id_embedding), dim=1)  # (batch_size, 788)\n",
    "\n",
    "        # ê°ì • ë° ìƒí™© ì˜ˆì¸¡\n",
    "        emotion_logits = self.emotion_classifier(combined_output)\n",
    "        situation_logits = self.situation_classifier(pooled_output)\n",
    "\n",
    "        return emotion_logits, situation_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7da63dc0-d501-4341-b268-75a8b1cf4a1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 8, got 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 85\u001b[0m\n\u001b[0;32m     82\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# í‰ê°€\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m test_loss, emotion_accuracy, situation_accuracy, emotion_f1, situation_f1, emotion_exact_match, situation_exact_match \u001b[38;5;241m=\u001b[39m evaluate_model(\n\u001b[0;32m     86\u001b[0m     model, test_dataloader, nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(), device, emotion_encoder, situation_encoder\n\u001b[0;32m     87\u001b[0m )\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# ê²°ê³¼ ì¶œë ¥\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Test Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[53], line 19\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, test_dataloader, loss_fn, device, emotion_encoder, situation_encoder)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m test_dataloader:\n\u001b[1;32m---> 19\u001b[0m         input_ids, attention_mask, token_type_ids, persona_id, emotion_id, pca_features, emotion_labels, situation_labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m     20\u001b[0m         input_ids \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     21\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m attention_mask\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 8, got 7)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate_model(model, test_dataloader, loss_fn, device, emotion_encoder, situation_encoder):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_emotion = 0\n",
    "    correct_situation = 0\n",
    "    total_emotion = 0\n",
    "    total_situation = 0\n",
    "    all_emotion_preds = []\n",
    "    all_situation_preds = []\n",
    "    all_emotion_labels = []\n",
    "    all_situation_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            input_ids, attention_mask, token_type_ids, persona_id, emotion_id, pca_features, emotion_labels, situation_labels = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "            persona_id = persona_id.to(device)\n",
    "            emotion_id = emotion_id.to(device)\n",
    "            pca_features = pca_features.to(device)  # PCA featureê°€ ìˆë‹¤ë©´ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ\n",
    "            emotion_labels = emotion_labels.to(device)\n",
    "            situation_labels = situation_labels.to(device)\n",
    "\n",
    "            # ëª¨ë¸ì— ì…ë ¥\n",
    "            emotion_logits, situation_logits = model(input_ids, attention_mask, token_type_ids, persona_id, emotion_id, pca_features)\n",
    "\n",
    "            # ì†ì‹¤ ê³„ì‚°\n",
    "            loss = loss_fn(emotion_logits, emotion_labels) + loss_fn(situation_logits, situation_labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # ì˜ˆì¸¡ê°’ ì–»ê¸°\n",
    "            emotion_pred = torch.argmax(emotion_logits, dim=1)\n",
    "            situation_pred = torch.argmax(situation_logits, dim=1)\n",
    "\n",
    "            # ì •í™•ë„ ê³„ì‚°\n",
    "            correct_emotion += (emotion_pred == emotion_labels).sum().item()\n",
    "            correct_situation += (situation_pred == situation_labels).sum().item()\n",
    "\n",
    "            total_emotion += emotion_labels.size(0)\n",
    "            total_situation += situation_labels.size(0)\n",
    "\n",
    "            # ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ì €ì¥\n",
    "            all_emotion_preds.extend(emotion_pred.cpu().numpy())\n",
    "            all_situation_preds.extend(situation_pred.cpu().numpy())\n",
    "            all_emotion_labels.extend(emotion_labels.cpu().numpy())\n",
    "            all_situation_labels.extend(situation_labels.cpu().numpy())\n",
    "\n",
    "    # í‰ê·  ì†ì‹¤ ê³„ì‚°\n",
    "    avg_loss = total_loss / len(test_dataloader)\n",
    "\n",
    "    # ê°ì •ê³¼ ìƒí™© ì •í™•ë„ ê³„ì‚°\n",
    "    emotion_accuracy = correct_emotion / total_emotion\n",
    "    situation_accuracy = correct_situation / total_situation\n",
    "\n",
    "    # F1-Score ê³„ì‚° (ê°ì •, ìƒí™©)\n",
    "    emotion_f1 = f1_score(all_emotion_labels, all_emotion_preds, average='weighted')\n",
    "    situation_f1 = f1_score(all_situation_labels, all_situation_preds, average='weighted')\n",
    "\n",
    "    # Exact Match ê³„ì‚°\n",
    "    emotion_exact_match = (emotion_encoder.inverse_transform(all_emotion_labels) == emotion_encoder.inverse_transform(all_emotion_preds)).mean()\n",
    "    situation_exact_match = (situation_encoder.inverse_transform(all_situation_labels) == situation_encoder.inverse_transform(all_situation_preds)).mean()\n",
    "\n",
    "    return avg_loss, emotion_accuracy, situation_accuracy, emotion_f1, situation_f1, emotion_exact_match, situation_exact_match\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model_name = \"monologg/kobert\"  # KoBERT ëª¨ë¸ëª…\n",
    "num_emotions = len(final_df[\"emotion\"].unique())  # ê°ì • í´ë˜ìŠ¤ ê°œìˆ˜\n",
    "num_situations = len(final_df[\"situation\"].unique())  # ìƒí™© í´ë˜ìŠ¤ ê°œìˆ˜\n",
    "model = KoBERTMultiOutputWithEmbedding(model_name, num_emotions, num_situations, num_personas, num_emotion_ids)\n",
    "\n",
    "# device ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# best_model.pth ë¡œë“œ\n",
    "model.load_state_dict(torch.load(\"kobert_emotion_situation/best_model.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "# í‰ê°€\n",
    "test_loss, emotion_accuracy, situation_accuracy, emotion_f1, situation_f1, emotion_exact_match, situation_exact_match = evaluate_model(\n",
    "    model, test_dataloader, nn.CrossEntropyLoss(), device, emotion_encoder, situation_encoder\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"âœ… Test Loss: {test_loss:.4f}\")\n",
    "print(f\"âœ… Emotion Accuracy: {emotion_accuracy:.4f}\")\n",
    "print(f\"âœ… Situation Accuracy: {situation_accuracy:.4f}\")\n",
    "print(f\"âœ… Emotion F1-Score: {emotion_f1:.4f}\")\n",
    "print(f\"âœ… Situation F1-Score: {situation_f1:.4f}\")\n",
    "print(f\"âœ… Emotion Exact Match: {emotion_exact_match:.4f}\")\n",
    "print(f\"âœ… Situation Exact Match: {situation_exact_match:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7786500d-472d-487c-a744-307c39642ba8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "KoBERTMultiOutputWithEmbedding.__init__() missing 2 required positional arguments: 'num_personas' and 'num_emotion_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# âœ… 3. ëª¨ë¸ ì´ˆê¸°í™”\u001b[39;00m\n\u001b[0;32m     13\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonologg/kobert\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# KoBERT ëª¨ë¸ëª…\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m model \u001b[38;5;241m=\u001b[39m KoBERTMultiOutputWithEmbedding(model_name, num_emotions, num_situations)  \u001b[38;5;66;03m# num_emotions, num_situations ì •ì˜ ì™„ë£Œ\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# âœ… 4. device ì„¤ì • (GPU/CPU)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# CUDA (GPU) ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: KoBERTMultiOutputWithEmbedding.__init__() missing 2 required positional arguments: 'num_personas' and 'num_emotion_ids'"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from transformers import BertModel, AutoTokenizer\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# # âœ… 2. ê°ì •ê³¼ ìƒí™©ì˜ í´ë˜ìŠ¤ ìˆ˜ ê³„ì‚°\n",
    "# num_emotions = len(final_df[\"emotion\"].unique())  # ê°ì • í´ë˜ìŠ¤ ê°œìˆ˜\n",
    "# num_situations = len(final_df[\"situation\"].unique())  # ìƒí™© í´ë˜ìŠ¤ ê°œìˆ˜\n",
    "\n",
    "# # âœ… 3. ëª¨ë¸ ì´ˆê¸°í™”\n",
    "# model_name = \"monologg/kobert\"  # KoBERT ëª¨ë¸ëª…\n",
    "# model = KoBERTMultiOutputWithEmbedding(model_name, num_emotions, num_situations)  # num_emotions, num_situations ì •ì˜ ì™„ë£Œ\n",
    "\n",
    "# # âœ… 4. device ì„¤ì • (GPU/CPU)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # CUDA (GPU) ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
    "# model.to(device)  # ëª¨ë¸ì„ í•´ë‹¹ deviceë¡œ ì´ë™\n",
    "\n",
    "# # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# model.load_state_dict(torch.load(\"kobert_emotion_situation/best_model.pth\"))\n",
    "# model.to(device)  # ë‹¤ì‹œ deviceë¡œ ëª¨ë¸ ì´ë™\n",
    "\n",
    "# # âœ… 5. í•™ìŠµ ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "# history = torch.load(\"kobert_emotion_situation/history.pth\", weights_only=True)\n",
    "# train_loss_history = history['train_loss']\n",
    "# train_accuracy_history = history['train_accuracy']\n",
    "\n",
    "# # âœ… 6. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì¤€ë¹„ (test_dataloader)\n",
    "# test_texts = test_df[\"text\"].tolist()  # 'text' ì»¬ëŸ¼ì— í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ìˆë‹¤ê³  ê°€ì •\n",
    "# test_encodings = tokenizer(test_texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "# emotion_labels_test = emotion_encoder.transform(test_df['emotion'].values)  # ê°ì • ë¼ë²¨\n",
    "# situation_labels_test = situation_encoder.transform(test_df['situation'].values)  # ìƒí™© ë¼ë²¨\n",
    "\n",
    "# # í…ì„œë¡œ ë³€í™˜\n",
    "# emotion_labels_test = torch.tensor(emotion_labels_test)\n",
    "# situation_labels_test = torch.tensor(situation_labels_test)\n",
    "\n",
    "# # Test Datasetê³¼ DataLoader ìƒì„±\n",
    "# test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_encodings['token_type_ids'],\n",
    "#                              emotion_labels_test, situation_labels_test)\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "# # âœ… 7. ëª¨ë¸ í‰ê°€ í•¨ìˆ˜ (F1-Scoreì™€ Exact Match ì¶”ê°€)\n",
    "# def evaluate_model(model, test_dataloader, loss_fn, device, emotion_encoder, situation_encoder):\n",
    "#     model.eval()\n",
    "#     total_loss = 0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     all_emotion_preds = []\n",
    "#     all_situation_preds = []\n",
    "#     all_emotion_labels = []\n",
    "#     all_situation_labels = []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for batch in test_dataloader:\n",
    "#             input_ids, attention_mask, token_type_ids, emotion_labels, situation_labels = batch\n",
    "#             input_ids = input_ids.to(device)\n",
    "#             attention_mask = attention_mask.to(device)\n",
    "#             token_type_ids = token_type_ids.to(device)\n",
    "#             emotion_labels = emotion_labels.to(device)\n",
    "#             situation_labels = situation_labels.to(device)\n",
    "\n",
    "#             emotion_logits, situation_logits = model(input_ids, attention_mask, token_type_ids)\n",
    "#             loss = loss_fn(emotion_logits, emotion_labels) + loss_fn(situation_logits, situation_labels)\n",
    "\n",
    "#             total_loss += loss.item()\n",
    "\n",
    "#             emotion_pred = torch.argmax(emotion_logits, dim=1)\n",
    "#             situation_pred = torch.argmax(situation_logits, dim=1)\n",
    "\n",
    "#             correct += (emotion_pred == emotion_labels).sum().item()\n",
    "#             correct += (situation_pred == situation_labels).sum().item()\n",
    "#             total += emotion_labels.size(0) + situation_labels.size(0)\n",
    "\n",
    "#             all_emotion_preds.extend(emotion_pred.cpu().numpy())\n",
    "#             all_situation_preds.extend(situation_pred.cpu().numpy())\n",
    "#             all_emotion_labels.extend(emotion_labels.cpu().numpy())\n",
    "#             all_situation_labels.extend(situation_labels.cpu().numpy())\n",
    "\n",
    "#     avg_loss = total_loss / len(test_dataloader)\n",
    "#     accuracy = correct / total\n",
    "\n",
    "#     # ê°ì •ê³¼ ìƒí™©ì— ëŒ€í•´ F1-Score ê³„ì‚°\n",
    "#     emotion_f1 = f1_score(all_emotion_labels, all_emotion_preds, average='weighted')\n",
    "#     situation_f1 = f1_score(all_situation_labels, all_situation_preds, average='weighted')\n",
    "\n",
    "#     # Exact Match ê³„ì‚° (TrueëŠ” 1.0, FalseëŠ” 0.0ìœ¼ë¡œ ë³€í™˜)\n",
    "#     # ì˜ˆì¸¡ê°’ì„ ë””ì½”ë”©í•˜ì—¬ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸\n",
    "#     emotion_exact_match = (emotion_encoder.inverse_transform(all_emotion_labels) == emotion_encoder.inverse_transform(all_emotion_preds)).mean()\n",
    "#     situation_exact_match = (situation_encoder.inverse_transform(all_situation_labels) == situation_encoder.inverse_transform(all_situation_preds)).mean()\n",
    "\n",
    "#     # ê°ì • ì •í™•ë„, ìƒí™© ì •í™•ë„ ê³„ì‚°\n",
    "#     emotion_accuracy = accuracy_score(all_emotion_labels, all_emotion_preds)\n",
    "#     situation_accuracy = accuracy_score(all_situation_labels, all_situation_preds)\n",
    "\n",
    "#     return avg_loss, accuracy, emotion_accuracy, situation_accuracy, emotion_f1, situation_f1, emotion_exact_match, situation_exact_match\n",
    "\n",
    "\n",
    "\n",
    "# # âœ… 8. ì†ì‹¤ í•¨ìˆ˜ ì •ì˜\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# # âœ… 9. ëª¨ë¸ í‰ê°€ ì‹¤í–‰\n",
    "# test_loss, test_accuracy, emotion_accuracy, situation_accuracy, emotion_f1, situation_f1, emotion_exact_match, situation_exact_match = evaluate_model(\n",
    "#     model, test_dataloader, loss_fn, device, emotion_encoder, situation_encoder\n",
    "# )\n",
    "\n",
    "\n",
    "# # âœ… 10. ê²°ê³¼ ì¶œë ¥\n",
    "# print(f\"âœ… Test Loss: {test_loss:.4f}\")\n",
    "# print(f\"âœ… Test Accuracy: {test_accuracy:.4f}\")\n",
    "# print(f\"âœ… Emotion Accuracy: {emotion_accuracy:.4f}\")\n",
    "# print(f\"âœ… Situation Accuracy: {situation_accuracy:.4f}\")\n",
    "# print(f\"âœ… Emotion F1-Score: {emotion_f1:.4f}\")\n",
    "# print(f\"âœ… Situation F1-Score: {situation_f1:.4f}\")\n",
    "# print(f\"âœ… Emotion Exact Match: {emotion_exact_match:.4f}\")\n",
    "# print(f\"âœ… Situation Exact Match: {situation_exact_match:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa0e1c8-769b-4c1b-9546-977f7beddaf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e335fb31-205a-42b7-b886-4b1a0a3b8002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a44901-b63a-4f57-b202-dcf683e2979e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
