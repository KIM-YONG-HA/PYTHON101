{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0968e29d-3099-4b18-ba36-8364cf70580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_binance_price():\n",
    "    \"\"\"바이낸스에서 SHIBUSDT 가격 가져오기\"\"\"\n",
    "    url = \"https://api.binance.com/api/v3/ticker/price\"\n",
    "    params = {\"symbol\": \"SHIBUSDT\"}\n",
    "    response = requests.get(url, params=params)\n",
    "    return float(response.json()[\"price\"])\n",
    "\n",
    "def get_upbit_price():\n",
    "    \"\"\"업비트에서 SHIB/KRW 가격 가져오기\"\"\"\n",
    "    url = \"https://api.upbit.com/v1/ticker\"\n",
    "    params = {\"markets\": \"KRW-SHIB\"}\n",
    "    response = requests.get(url, params=params)\n",
    "    return float(response.json()[0][\"trade_price\"])\n",
    "\n",
    "def get_usd_to_krw():\n",
    "    \"\"\"신뢰할 수 있는 API에서 환율 가져오기 (네이버 금융)\"\"\"\n",
    "    url = \"https://api.exchangerate-api.com/v4/latest/USD\"  # 신뢰할 수 있는 환율 API\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    return float(data[\"rates\"][\"KRW\"])  # USD → KRW 환율 값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35fd2f0e-94b0-4ea8-8352-ef0736ec9052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 SHIB 현재 가격 (업비트): 0.01918 KRW\n",
      "📌 SHIB 현재 가격 (바이낸스): 1.273e-05 USDT\n",
      "📌 환율 (USD → KRW): 1458.82\n",
      "🔥 김치 프리미엄: 3.28%\n"
     ]
    }
   ],
   "source": [
    "# 실시간 데이터 가져오기\n",
    "binance_price = get_binance_price()  # 바이낸스 가격 (USDT)\n",
    "upbit_price = get_upbit_price()  # 업비트 가격 (KRW)\n",
    "usd_to_krw = get_usd_to_krw()  # 환율\n",
    "\n",
    "# 김치 프리미엄 계산\n",
    "kimchi_premium = ((upbit_price / (binance_price * usd_to_krw)) - 1) * 100\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"📌 SHIB 현재 가격 (업비트): {upbit_price} KRW\")\n",
    "print(f\"📌 SHIB 현재 가격 (바이낸스): {binance_price} USDT\")\n",
    "print(f\"📌 환율 (USD → KRW): {usd_to_krw}\")\n",
    "print(f\"🔥 김치 프리미엄: {kimchi_premium:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b23d48d-294c-47fb-a48d-5a5d1b174c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ✅ 📌 데이터 로드 (거래량 포함)\n",
    "df = pd.read_csv(\"data/shib.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b413b43b-6528-439d-998e-72fae638e4a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-10 11:00:00</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>1.527431e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-10 12:00:00</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>1.290046e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-10 13:00:00</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>8.472225e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-10 14:00:00</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>5.786327e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-10 15:00:00</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>3.593920e+12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp      open      high       low     close        volume\n",
       "0  2021-05-10 11:00:00  0.000014  0.000050  0.000014  0.000030  1.527431e+13\n",
       "1  2021-05-10 12:00:00  0.000030  0.000039  0.000029  0.000033  1.290046e+13\n",
       "2  2021-05-10 13:00:00  0.000033  0.000036  0.000029  0.000031  8.472225e+12\n",
       "3  2021-05-10 14:00:00  0.000031  0.000031  0.000028  0.000029  5.786327e+12\n",
       "4  2021-05-10 15:00:00  0.000029  0.000031  0.000029  0.000029  3.593920e+12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c322f471-7538-407e-a468-5f55b826dd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33444 entries, 0 to 33443\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   timestamp  33444 non-null  object \n",
      " 1   open       33444 non-null  float64\n",
      " 2   high       33444 non-null  float64\n",
      " 3   low        33444 non-null  float64\n",
      " 4   close      33444 non-null  float64\n",
      " 5   volume     33444 non-null  float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c5bfe66-3d65-458d-8b9e-f2b9e85289a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kj\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m835/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 8.6434e-04 - mae: 0.0129\n",
      "Epoch 1: val_loss improved from inf to 0.00005, saving model to best_model2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m835/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 43ms/step - loss: 8.6373e-04 - mae: 0.0129 - val_loss: 4.9449e-05 - val_mae: 0.0061\n",
      "Epoch 2/50\n",
      "\u001b[1m835/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1.8225e-04 - mae: 0.0077\n",
      "Epoch 2: val_loss did not improve from 0.00005\n",
      "\u001b[1m835/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 42ms/step - loss: 1.8226e-04 - mae: 0.0077 - val_loss: 6.0302e-05 - val_mae: 0.0068\n",
      "Epoch 3/50\n",
      "\u001b[1m835/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1.5091e-04 - mae: 0.0074\n",
      "Epoch 3: val_loss improved from 0.00005 to 0.00001, saving model to best_model2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m835/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 42ms/step - loss: 1.5092e-04 - mae: 0.0074 - val_loss: 1.1654e-05 - val_mae: 0.0023\n",
      "Epoch 4/50\n",
      "\u001b[1m835/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1.6243e-04 - mae: 0.0079\n",
      "Epoch 4: val_loss did not improve from 0.00001\n",
      "\u001b[1m835/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 42ms/step - loss: 1.6242e-04 - mae: 0.0079 - val_loss: 3.7424e-05 - val_mae: 0.0048\n",
      "Epoch 5/50\n",
      "\u001b[1m835/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.5680e-04 - mae: 0.0078\n",
      "Epoch 5: val_loss improved from 0.00001 to 0.00001, saving model to best_model2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m835/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 42ms/step - loss: 1.5678e-04 - mae: 0.0078 - val_loss: 9.8443e-06 - val_mae: 0.0022\n",
      "Epoch 6/50\n",
      "\u001b[1m835/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.4133e-04 - mae: 0.0075\n",
      "Epoch 6: val_loss did not improve from 0.00001\n",
      "\u001b[1m835/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 42ms/step - loss: 1.4134e-04 - mae: 0.0075 - val_loss: 1.0773e-05 - val_mae: 0.0023\n",
      "Epoch 7/50\n",
      "\u001b[1m834/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1.3176e-04 - mae: 0.0071\n",
      "Epoch 7: val_loss did not improve from 0.00001\n",
      "\u001b[1m835/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 42ms/step - loss: 1.3181e-04 - mae: 0.0071 - val_loss: 6.4080e-05 - val_mae: 0.0072\n",
      "Epoch 8/50\n",
      "\u001b[1m834/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 1.3720e-04 - mae: 0.0073\n",
      "Epoch 8: val_loss did not improve from 0.00001\n",
      "\u001b[1m835/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 42ms/step - loss: 1.3718e-04 - mae: 0.0073 - val_loss: 4.4469e-05 - val_mae: 0.0062\n",
      "Epoch 9/50\n",
      "\u001b[1m834/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.2586e-04 - mae: 0.0072\n",
      "Epoch 9: val_loss did not improve from 0.00001\n",
      "\u001b[1m835/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 42ms/step - loss: 1.2588e-04 - mae: 0.0072 - val_loss: 1.3437e-05 - val_mae: 0.0031\n",
      "Epoch 10/50\n",
      "\u001b[1m835/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 1.1417e-04 - mae: 0.0067\n",
      "Epoch 10: val_loss did not improve from 0.00001\n",
      "\u001b[1m835/835\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 41ms/step - loss: 1.1418e-04 - mae: 0.0067 - val_loss: 1.9907e-05 - val_mae: 0.0035\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 5.\n",
      "Training Loss: 0.000121\n",
      "Validation Loss: 0.000020\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ✅ 📌 데이터 로드\n",
    "df = pd.read_csv(\"data/shib.csv\")\n",
    "\n",
    "# ✅ 📌 타임스탬프 변환\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "\n",
    "# ✅ 📌 정규화 (MinMaxScaler 적용)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(df[[\"open\", \"high\", \"low\", \"close\", \"volume\"]])\n",
    "\n",
    "# 🔥 학습 데이터 생성 (시퀀스 형태 변환)\n",
    "def create_sequences(data, seq_length=50):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])  # 과거 시퀀스\n",
    "        y.append(data[i+seq_length, 3])  # 📌 `close` 값 예측 (네 번째 컬럼)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# ✅ 시퀀스 데이터 생성\n",
    "SEQ_LENGTH = 50\n",
    "X, y = create_sequences(scaled_data, seq_length=SEQ_LENGTH)\n",
    "\n",
    "# ✅ 데이터 분리 (80% 학습, 10% 검증, 10% 테스트)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)\n",
    "\n",
    "# ✅ 📌 새로운 LSTM 모델 정의 (거래량 포함)\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(SEQ_LENGTH, X.shape[2])),  # 첫 번째 LSTM 레이어\n",
    "    Dropout(0.2),\n",
    "    LSTM(128, return_sequences=False),  # 두 번째 LSTM 레이어\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation=\"relu\"),  # 완전연결층\n",
    "    Dense(1)  # 출력층 (예측할 `close` 값)\n",
    "])\n",
    "\n",
    "# ✅ 모델 컴파일\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "\n",
    "# ✅ 체크포인트 설정 (Best 모델 저장)\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"best_model2.h5\",  # 저장될 모델 파일명\n",
    "    monitor=\"val_loss\",  # 검증 손실 기준\n",
    "    save_best_only=True,  # 가장 낮은 val_loss 모델만 저장\n",
    "    mode=\"min\",  # val_loss 최소화 기준\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ✅ EarlyStopping 추가 (과적합 방지)\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",  # 검증 손실 기준\n",
    "    patience=5,  # 5번 연속 val_loss 감소 없으면 중단\n",
    "    restore_best_weights=True,  # 가장 좋은 모델로 복구\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ✅ 모델 학습\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")\n",
    "\n",
    "# ✅ 최종 모델 저장\n",
    "#model.save(\"final_model.h5\")\n",
    "\n",
    "# ✅ 학습 결과 확인\n",
    "print(f\"Training Loss: {history.history['loss'][-1]:.6f}\")\n",
    "print(f\"Validation Loss: {history.history['val_loss'][-1]:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a138e9-807e-4642-b39b-160f6b64c510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1863c567-fc3c-4cf2-9455-cfa38d4fb170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319be8b8-9b7b-457f-ad20-198445ef0b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0946ad6b-02fe-4c07-a020-4b500ac58e15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ac3244d-1ebf-43a4-86c2-991727b0395a",
   "metadata": {},
   "source": [
    "## 예측 및 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069f7aa9-f15a-433d-a8aa-ecfcb3c5aa6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
