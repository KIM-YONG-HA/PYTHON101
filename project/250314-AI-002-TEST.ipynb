{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc6b606a-fca7-4bc5-9f05-413fe33b39a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ì €ì¥ëœ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "final_df = pd.read_csv('data/final_df_preprocessed.csv', encoding='utf-8-sig')\n",
    "test_df = pd.read_csv('data/test_df_preprocessed.csv', encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e21ee9d0-9f39-4ca3-8c85-55ca3657de37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  persona-id  emotion-id  \\\n",
      "0              í•´ë„ ì—†ì„ê¹Œ í™”ê°€ ë‚œë‹¤ ê·¸ëƒ¥ í•´ê²° í•˜ëŠ” ë‚˜ì•„ ë¶€ë‹´ ì£¼ê³  ì‹¶ì§€ë„ ì•Šê³            3         368   \n",
      "1  ê¸‰ì—¬ ê¹ì˜€ì–´ ë¬¼ê°€ ì˜¤ë¥´ëŠ”ë° ì›”ê¸‰ ìê¾¸ ê¹ì´ë‹ˆê¹Œ ë„ˆë¬´ í™”ê°€ ìµœëŒ€í•œ ì§€ì¶œ ì–µì œ í•´ì•¼ê² ì–´...           3         368   \n",
      "2  íšŒì‚¬ ì‹ ì… ë“¤ì–´ì™”ëŠ”ë° ë§íˆ¬ ê±°ìŠ¬ë ¤ ê·¸ëŸ° ë§¤ì¼ ë´ì•¼ í•œë‹¤ê³  ìƒê° í•˜ë‹ˆê¹Œ ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•„...           3         368   \n",
      "3  ì§ì¥ ë§‰ë‚´ ì´ìœ  ì˜¨ê°– ì‹¬ë¶€ë¦„ ì‹œì¼œ ì¼ë„ ë§ì€ ì •ë§ ë¶„í•˜ê³  ì„­ì„­í•´ ì‚¬ëŒ ì†”ì§í•˜ê²Œ ì´ì•¼...           3         368   \n",
      "4  ì…ì‚¬ ì‹ ì…ì‚¬ì› ë‚˜ë¥¼ ë¬´ì‹œ í•˜ëŠ” ê°™ì•„ì„œ ë„ˆë¬´ í™”ê°€ ìƒì‚¬ ë¨¼ì € ì¸ì‚¬ í•˜ì§€ ì•Šì•„ì„œ ë§¤ì¼ í•œë‹¤ê³            3         368   \n",
      "\n",
      "   emotion  situation  disease  text_pca_1  text_pca_2  \n",
      "0        8          5        1   -0.045439    0.059560  \n",
      "1        8          5        1    0.036776    0.019723  \n",
      "2        8          5        1   -0.196787    0.278481  \n",
      "3        8          5        1   -0.082461    0.201029  \n",
      "4        8          5        1    0.063519    0.064646  \n",
      "                                                text  persona-id  emotion-id  \\\n",
      "0  ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„œ ë°œí‘œë¥¼ í•˜ëŠ”ë° ë‚´ê°€ ì‹¤ìˆ˜í•˜ëŠ” ë°”ëŒì— ìš°ë¦¬ íŒ€ì´ ê°ì ì„ ë°›ì•˜ì–´ ë„ˆë¬´...           2         381   \n",
      "1  íšŒì‚¬ì—ì„œ ì¤‘ìš”í•œ í”„ë¡œì íŠ¸ë¥¼ í˜¼ì í•˜ê²Œ ëëŠ”ë° ì†”ì§íˆ ë‘ë µê³  ë¬´ì„œì›Œ ë‚˜ì—ê²Œ ë„ˆë¬´ í¬ê²Œ...           2         381   \n",
      "2  ìƒì‚¬ê°€ ë„ˆë¬´ ë¬´ì„­ê²Œ ìƒê²¨ì„œ ì¹œí•´ì§€ëŠ” ê²Œ ë„ˆë¬´ ë‘ë ¤ì›Œ ë¬´ì„­ê²Œ ìƒê²¼ëŠ”ë°ë„ ì—…ë¬´ë¥¼ ë³´ë ¤ë©´...           2         381   \n",
      "3  ì´ë²ˆì— í˜ë“¤ê²Œ ë“¤ì–´ê°„ ì²« ì§ì¥ì´ê±°ë“  ì²« ì§ì¥ì´ë¼ì„œ ê·¸ëŸ°ì§€ ë„ˆë¬´ ê¸´ì¥ëœë‹¤ ì²« ì§ì¥ì´ì–´...           2         381   \n",
      "4  ì§ì¥ì—ì„œ ë™ë£Œë“¤ì´ë‘ ê´€ê³„ê°€ ì•ˆ ì¢‹ì•„ì§ˆê¹Œ ë´ ê±±ì •ë¼ ë‚´ê°€ ë‚¯ê°€ë¦¼ì´ ì‹¬í•´ì„œ ì¹œí•´ì§ˆ ìˆ˜ ...           2         381   \n",
      "\n",
      "   emotion  situation  disease  text_pca_1  text_pca_2  \n",
      "0       21          5        1   -0.001888   -0.313635  \n",
      "1       21          5        1    0.011658   -0.092545  \n",
      "2       21          5        1    0.147893   -0.197571  \n",
      "3       21          5        1   -0.006208   -0.136605  \n",
      "4       21          5        1   -0.133726    0.267530  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a00eaec0-cb85-437f-baa8-13abc987fb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ê°ì • ë¼ë²¨ ì¸ì½”ë”©\n",
    "emotion_encoder = LabelEncoder()\n",
    "final_df[\"emotion\"] = emotion_encoder.fit_transform(final_df[\"emotion\"])\n",
    "test_df[\"emotion\"] = emotion_encoder.transform(test_df[\"emotion\"])\n",
    "\n",
    "# ìƒí™© ë¼ë²¨ ì¸ì½”ë”©\n",
    "situation_encoder = LabelEncoder()\n",
    "final_df[\"situation\"] = situation_encoder.fit_transform(final_df[\"situation\"])\n",
    "test_df[\"situation\"] = situation_encoder.transform(test_df[\"situation\"])\n",
    "\n",
    "# ì§ˆë³‘ ë¼ë²¨ ì¸ì½”ë”©\n",
    "disease_encoder = LabelEncoder()\n",
    "final_df[\"disease\"] = disease_encoder.fit_transform(final_df[\"disease\"])\n",
    "test_df[\"disease\"] = disease_encoder.transform(test_df[\"disease\"])\n",
    "\n",
    "# ë ˆì´ë¸” ì¸ì½”ë”©: persona-id, emotion-id ìˆ«ìë¡œ ë³€í™˜\n",
    "persona_encoder = LabelEncoder()\n",
    "final_df['persona-id'] = persona_encoder.fit_transform(final_df['persona-id'])\n",
    "test_df['persona-id'] = persona_encoder.transform(test_df['persona-id'])\n",
    "\n",
    "emotionid_encoder = LabelEncoder()\n",
    "final_df['emotion-id'] = emotionid_encoder.fit_transform(final_df['emotion-id'])\n",
    "test_df['emotion-id'] = emotionid_encoder.transform(test_df['emotion-id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e2e5265-f328-4797-b3fe-30e334ef6c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  persona-id  emotion-id  \\\n",
      "0              í•´ë„ ì—†ì„ê¹Œ í™”ê°€ ë‚œë‹¤ ê·¸ëƒ¥ í•´ê²° í•˜ëŠ” ë‚˜ì•„ ë¶€ë‹´ ì£¼ê³  ì‹¶ì§€ë„ ì•Šê³            3         368   \n",
      "1  ê¸‰ì—¬ ê¹ì˜€ì–´ ë¬¼ê°€ ì˜¤ë¥´ëŠ”ë° ì›”ê¸‰ ìê¾¸ ê¹ì´ë‹ˆê¹Œ ë„ˆë¬´ í™”ê°€ ìµœëŒ€í•œ ì§€ì¶œ ì–µì œ í•´ì•¼ê² ì–´...           3         368   \n",
      "2  íšŒì‚¬ ì‹ ì… ë“¤ì–´ì™”ëŠ”ë° ë§íˆ¬ ê±°ìŠ¬ë ¤ ê·¸ëŸ° ë§¤ì¼ ë´ì•¼ í•œë‹¤ê³  ìƒê° í•˜ë‹ˆê¹Œ ìŠ¤íŠ¸ë ˆìŠ¤ ë°›ì•„...           3         368   \n",
      "3  ì§ì¥ ë§‰ë‚´ ì´ìœ  ì˜¨ê°– ì‹¬ë¶€ë¦„ ì‹œì¼œ ì¼ë„ ë§ì€ ì •ë§ ë¶„í•˜ê³  ì„­ì„­í•´ ì‚¬ëŒ ì†”ì§í•˜ê²Œ ì´ì•¼...           3         368   \n",
      "4  ì…ì‚¬ ì‹ ì…ì‚¬ì› ë‚˜ë¥¼ ë¬´ì‹œ í•˜ëŠ” ê°™ì•„ì„œ ë„ˆë¬´ í™”ê°€ ìƒì‚¬ ë¨¼ì € ì¸ì‚¬ í•˜ì§€ ì•Šì•„ì„œ ë§¤ì¼ í•œë‹¤ê³            3         368   \n",
      "\n",
      "   emotion  situation  disease  text_pca_1  text_pca_2  \n",
      "0        8          5        1   -0.045439    0.059560  \n",
      "1        8          5        1    0.036776    0.019723  \n",
      "2        8          5        1   -0.196787    0.278481  \n",
      "3        8          5        1   -0.082461    0.201029  \n",
      "4        8          5        1    0.063519    0.064646  \n",
      "                                                text  persona-id  emotion-id  \\\n",
      "0  ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„œ ë°œí‘œë¥¼ í•˜ëŠ”ë° ë‚´ê°€ ì‹¤ìˆ˜í•˜ëŠ” ë°”ëŒì— ìš°ë¦¬ íŒ€ì´ ê°ì ì„ ë°›ì•˜ì–´ ë„ˆë¬´...           2         381   \n",
      "1  íšŒì‚¬ì—ì„œ ì¤‘ìš”í•œ í”„ë¡œì íŠ¸ë¥¼ í˜¼ì í•˜ê²Œ ëëŠ”ë° ì†”ì§íˆ ë‘ë µê³  ë¬´ì„œì›Œ ë‚˜ì—ê²Œ ë„ˆë¬´ í¬ê²Œ...           2         381   \n",
      "2  ìƒì‚¬ê°€ ë„ˆë¬´ ë¬´ì„­ê²Œ ìƒê²¨ì„œ ì¹œí•´ì§€ëŠ” ê²Œ ë„ˆë¬´ ë‘ë ¤ì›Œ ë¬´ì„­ê²Œ ìƒê²¼ëŠ”ë°ë„ ì—…ë¬´ë¥¼ ë³´ë ¤ë©´...           2         381   \n",
      "3  ì´ë²ˆì— í˜ë“¤ê²Œ ë“¤ì–´ê°„ ì²« ì§ì¥ì´ê±°ë“  ì²« ì§ì¥ì´ë¼ì„œ ê·¸ëŸ°ì§€ ë„ˆë¬´ ê¸´ì¥ëœë‹¤ ì²« ì§ì¥ì´ì–´...           2         381   \n",
      "4  ì§ì¥ì—ì„œ ë™ë£Œë“¤ì´ë‘ ê´€ê³„ê°€ ì•ˆ ì¢‹ì•„ì§ˆê¹Œ ë´ ê±±ì •ë¼ ë‚´ê°€ ë‚¯ê°€ë¦¼ì´ ì‹¬í•´ì„œ ì¹œí•´ì§ˆ ìˆ˜ ...           2         381   \n",
      "\n",
      "   emotion  situation  disease  text_pca_1  text_pca_2  \n",
      "0       21          5        1   -0.001888   -0.313635  \n",
      "1       21          5        1    0.011658   -0.092545  \n",
      "2       21          5        1    0.147893   -0.197571  \n",
      "3       21          5        1   -0.006208   -0.136605  \n",
      "4       21          5        1   -0.133726    0.267530  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "120f4c93-6ce8-423c-9e03-84961f20aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# ğŸ”¹ Step 1: í…ìŠ¤íŠ¸ ë°ì´í„° ë²¡í„°í™” (TF-IDF)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=100)  # ìµœëŒ€ 100ê°œ íŠ¹ì„± ì¶”ì¶œ\n",
    "\n",
    "# final_dfì—ì„œ TF-IDF ë²¡í„°í™”\n",
    "tfidf_matrix_train = tfidf_vectorizer.fit_transform(final_df['text'])\n",
    "\n",
    "# test_dfì—ì„œ TF-IDF ë²¡í„°í™” (í•™ìŠµëœ vectorizer ì‚¬ìš©)\n",
    "tfidf_matrix_test = tfidf_vectorizer.transform(test_df['text'])\n",
    "\n",
    "# ğŸ”¹ Step 2: í…ìŠ¤íŠ¸ ë°ì´í„° ì°¨ì› ì¶•ì†Œ (PCA)\n",
    "pca = PCA(n_components=2)  # 2Dë¡œ ì¶•ì†Œ\n",
    "\n",
    "# final_dfì—ì„œ PCA ì ìš©\n",
    "text_pca_train = pca.fit_transform(tfidf_matrix_train.toarray())\n",
    "\n",
    "# test_dfì—ì„œ PCA ì ìš© (í•™ìŠµëœ PCA ëª¨ë¸ ì‚¬ìš©)\n",
    "text_pca_test = pca.transform(tfidf_matrix_test.toarray())\n",
    "\n",
    "# ğŸ”¹ Step 3: í…ìŠ¤íŠ¸ ë²¡í„°í™”ëœ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€\n",
    "final_df['text_pca_1'] = text_pca_train[:, 0]\n",
    "final_df['text_pca_2'] = text_pca_train[:, 1]\n",
    "\n",
    "test_df['text_pca_1'] = text_pca_test[:, 0]\n",
    "test_df['text_pca_2'] = text_pca_test[:, 1]\n",
    "\n",
    "# ğŸ”¹ Step 4: ìƒê´€ í–‰ë ¬ ê³„ì‚°\n",
    "# ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì— ëŒ€í•´ì„œë§Œ ìƒê´€ ê´€ê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "correlation_matrix_train = final_df[['text_pca_1', 'text_pca_2', 'emotion', 'situation', 'persona-id', 'emotion-id']].apply(pd.to_numeric, errors='coerce').corr()\n",
    "\n",
    "# # ğŸ”¹ Step 5: ìƒê´€ í–‰ë ¬ ì‹œê°í™” (final_df)\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(correlation_matrix_train, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "# plt.title('Correlation Matrix: Text, Persona-id, Emotion-id, Emotion, Situation (Train Data)')\n",
    "# plt.show()\n",
    "\n",
    "# # ğŸ”¹ Step 6: ìƒí™©ì— ë”°ë¥¸ ê°ì • ë¶„í¬ (final_df)\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.countplot(data=final_df, x='situation', hue='emotion', palette='Set2')\n",
    "# plt.title('Emotion Distribution per Situation (Train Data)')\n",
    "# plt.xlabel('Situation')\n",
    "# plt.ylabel('Count')\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.legend(title='Emotion')\n",
    "# plt.show()\n",
    "\n",
    "# # ğŸ”¹ Step 7: í˜ë¥´ì†Œë‚˜ ì•„ì´ë””ì™€ ê°ì • ì•„ì´ë””ì— ë”°ë¥¸ ê°ì • ë¶„í¬ (final_df)\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# sns.countplot(data=final_df, x='persona-id', hue='emotion', palette='Set1')\n",
    "# plt.title('Emotion Distribution by Persona-id (Train Data)')\n",
    "# plt.xlabel('Persona-id')\n",
    "# plt.ylabel('Count')\n",
    "# plt.legend(title='Emotion')\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cb762c-962d-4ac0-8d85-265c16cdec6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636db661-7745-4661-9af9-3f829be76f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d20ef82-5d5b-4fc0-bc6e-c137556264ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len, pca_features=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.pca_features = pca_features  # PCA íŠ¹ì„± (ì„ íƒ ì‚¬í•­)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.dataframe.iloc[index]['text']\n",
    "        emotion = self.dataframe.iloc[index]['emotion']\n",
    "        situation = self.dataframe.iloc[index]['situation']\n",
    "        persona_id = self.dataframe.iloc[index]['persona-id']\n",
    "        emotion_id = self.dataframe.iloc[index]['emotion-id']\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        input_ids = encoding['input_ids'].squeeze(0)  # (1, seq_len) -> (seq_len,)\n",
    "        attention_mask = encoding['attention_mask'].squeeze(0)  # (1, seq_len) -> (seq_len,)\n",
    "        token_type_ids = encoding['token_type_ids'].squeeze(0) if 'token_type_ids' in encoding else torch.zeros_like(input_ids)\n",
    "\n",
    "        # pca_featuresë¥¼ í¬í•¨í•˜ë„ë¡ ìˆ˜ì •\n",
    "        pca_feature = self.pca_features[index] if self.pca_features is not None else torch.zeros(2)  # 2D PCA íŠ¹ì„± ì˜ˆì‹œ (í•„ìš”í•œ íŠ¹ì„±ì— ë§ê²Œ ìˆ˜ì •)\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'token_type_ids': token_type_ids,\n",
    "            'emotion': torch.tensor(emotion, dtype=torch.long),\n",
    "            'situation': torch.tensor(situation, dtype=torch.long),\n",
    "            'persona-id': torch.tensor(persona_id, dtype=torch.long),\n",
    "            'emotion-id': torch.tensor(emotion_id, dtype=torch.long),\n",
    "            'pca_features': pca_feature  # pca_features ì¶”ê°€\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f311c829-0d1b-40b1-b6f4-bc699ed170ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ì„¤ì •\n",
    "model_name = \"monologg/kobert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "# PCA ì ìš© (ì˜ˆì‹œ)\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=100)\n",
    "tfidf_matrix_train = tfidf_vectorizer.fit_transform(final_df['text'])\n",
    "\n",
    "# PCA ì ìš© (2Dë¡œ ì¶•ì†Œ)\n",
    "pca = PCA(n_components=2)\n",
    "pca_features_train = pca.fit_transform(tfidf_matrix_train.toarray())\n",
    "\n",
    "# ë°ì´í„°ì…‹ì— PCA íŠ¹ì„± ì¶”ê°€\n",
    "train_dataset = CustomDataset(final_df, tokenizer, max_len=128, pca_features=pca_features_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# PCA íŠ¹ì„±ì„ test ë°ì´í„°ì—ë„ ì ìš©\n",
    "tfidf_matrix_test = tfidf_vectorizer.transform(test_df['text'])\n",
    "pca_features_test = pca.transform(tfidf_matrix_test.toarray())\n",
    "\n",
    "test_dataset = CustomDataset(test_df, tokenizer, max_len=128, pca_features=pca_features_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# ì´ ë¶€ë¶„ì—ì„œ train_dataloaderì™€ test_dataloaderë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµ ë° í‰ê°€ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a80b6e81-59bf-4dbd-96b4-8deebe58dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class KoBERTMultiOutputWithEmbedding(nn.Module):\n",
    "    def __init__(self, model_name, num_emotions, num_situations, num_personas, num_emotion_ids, embedding_dim=10):\n",
    "        super(KoBERTMultiOutputWithEmbedding, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)  # KoBERT ê¸°ë³¸ ëª¨ë¸\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # ê°ì • ë¶„ë¥˜ ë ˆì´ì–´ (ì…ë ¥ í¬ê¸° í™•ì¸)\n",
    "        self.emotion_classifier = nn.Linear(768 + 2 * embedding_dim, num_emotions)  # BERT ì¶œë ¥ + ì„ë² ë”© ì°¨ì› í¬ê¸°\n",
    "        self.situation_classifier = nn.Linear(768, num_situations)  # ìƒí™© ì˜ˆì¸¡ì€ BERTë§Œ ì‚¬ìš©\n",
    "\n",
    "        # persona-idì™€ emotion-idë¥¼ ìœ„í•œ ì„ë² ë”© ë ˆì´ì–´\n",
    "        self.persona_embedding = nn.Embedding(num_personas, embedding_dim)  # persona-id ì„ë² ë”©\n",
    "        self.emotion_id_embedding = nn.Embedding(num_emotion_ids, embedding_dim)  # emotion-id ì„ë² ë”©\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, persona_id, emotion_id, pca_features):\n",
    "        # BERT ëª¨ë¸ì—ì„œ ì¶œë ¥ê°’ ì–»ê¸°\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = outputs.pooler_output  # (batch_size, 768)\n",
    "\n",
    "        # persona-idì™€ emotion-id ì„ë² ë”©\n",
    "        persona_embedding = self.persona_embedding(persona_id)  # (batch_size, embedding_dim)\n",
    "        emotion_id_embedding = self.emotion_id_embedding(emotion_id)  # (batch_size, embedding_dim)\n",
    "\n",
    "        # ì„ë² ë”© ë²¡í„°ë¥¼ BERT ì¶œë ¥ê³¼ ê²°í•©\n",
    "        combined_output = torch.cat((pooled_output, persona_embedding, emotion_id_embedding), dim=1)  # (batch_size, 788)\n",
    "\n",
    "        # ê°ì • ë° ìƒí™© ì˜ˆì¸¡\n",
    "        emotion_logits = self.emotion_classifier(combined_output)\n",
    "        situation_logits = self.situation_classifier(pooled_output)\n",
    "\n",
    "        return emotion_logits, situation_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7da63dc0-d501-4341-b268-75a8b1cf4a1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TensorDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m situation_labels_test \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(situation_labels_test)\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Test Datasetê³¼ DataLoader ìƒì„±\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m TensorDataset(test_encodings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m], test_encodings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m], test_encodings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     66\u001b[0m                              emotion_labels_test, situation_labels_test)\n\u001b[0;32m     67\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_model\u001b[39m(model, test_dataloader, loss_fn, device, emotion_encoder, situation_encoder):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TensorDataset' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW, get_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "from datetime import datetime\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ëª¨ë¸ ìƒì„± (train_dfì˜ ê°ì •, ìƒí™© ë ˆì´ë¸” ìˆ˜ì— ë§ì¶° ì„¤ì •)\n",
    "num_emotions = len(final_df[\"emotion\"].unique())  # ê°ì • í´ë˜ìŠ¤ ê°œìˆ˜\n",
    "num_situations = len(final_df[\"situation\"].unique())  # ìƒí™© í´ë˜ìŠ¤ ê°œìˆ˜\n",
    "num_personas = len(final_df[\"persona-id\"].unique())  # persona-id í´ë˜ìŠ¤ ê°œìˆ˜\n",
    "num_emotion_ids = len(final_df[\"emotion-id\"].unique())  # emotion-id í´ë˜ìŠ¤ ê°œìˆ˜\n",
    "embedding_dim = 10  # ì„ë² ë”© ì°¨ì› í¬ê¸°\n",
    "\n",
    "model_name = \"monologg/kobert\"\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = KoBERTMultiOutputWithEmbedding(model_name, num_emotions, num_situations, num_personas, num_emotion_ids, embedding_dim)\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU ë˜ëŠ” CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)  # ëª¨ë¸ì„ ì„¤ì •í•œ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
    "\n",
    "# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "emotion_labels = final_df['emotion'].values\n",
    "situation_labels = final_df['situation'].values\n",
    "\n",
    "# ê°ì •ê³¼ ìƒí™©ì— ëŒ€í•œ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "emotion_class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(emotion_labels), y=emotion_labels)\n",
    "situation_class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(situation_labels), y=situation_labels)\n",
    "\n",
    "# ê°€ì¤‘ì¹˜ë¥¼ í…ì„œë¡œ ë³€í™˜\n",
    "emotion_weights = torch.tensor(emotion_class_weights, dtype=torch.float).to(device)\n",
    "situation_weights = torch.tensor(situation_class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜ ì„¤ì • (ê°€ì¤‘ì¹˜ ì ìš©)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=emotion_weights)  # ê°ì • í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©\n",
    "situation_loss_fn = nn.CrossEntropyLoss(weight=situation_weights)  # ìƒí™© í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©\n",
    "\n",
    "# ì˜µí‹°ë§ˆì´ì € ë° í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, no_deprecation_warning=True)  # AdamW ì˜µí‹°ë§ˆì´ì € ì‚¬ìš©\n",
    "num_training_steps = len(train_dataloader) * 10  # í•™ìŠµí•  ì´ ìŠ¤í… ìˆ˜ \n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)  # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •\n",
    "\n",
    "\n",
    "# Test Datasetê³¼ DataLoader ìƒì„±\n",
    "test_texts = test_df[\"text\"].tolist()  # 'text' ì»¬ëŸ¼ì— í…ìŠ¤íŠ¸ê°€ ìˆë‹¤ê³  ê°€ì •\n",
    "test_encodings = tokenizer(test_texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "\n",
    "emotion_labels_test = emotion_encoder.transform(test_df['emotion'].values)  # ê°ì • ë¼ë²¨\n",
    "situation_labels_test = situation_encoder.transform(test_df['situation'].values)  # ìƒí™© ë¼ë²¨\n",
    "\n",
    "# í…ì„œë¡œ ë³€í™˜\n",
    "emotion_labels_test = torch.tensor(emotion_labels_test)\n",
    "situation_labels_test = torch.tensor(situation_labels_test)\n",
    "\n",
    "# Test Datasetê³¼ DataLoader ìƒì„±\n",
    "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_encodings['token_type_ids'],\n",
    "                             emotion_labels_test, situation_labels_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_dataloader, loss_fn, device, emotion_encoder, situation_encoder):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct_emotion = 0\n",
    "    correct_situation = 0\n",
    "    total_emotion = 0\n",
    "    total_situation = 0\n",
    "    all_emotion_preds = []\n",
    "    all_situation_preds = []\n",
    "    all_emotion_labels = []\n",
    "    all_situation_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            input_ids, attention_mask, token_type_ids, persona_id, emotion_id, pca_features, emotion_labels, situation_labels = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "            persona_id = persona_id.to(device)\n",
    "            emotion_id = emotion_id.to(device)\n",
    "            pca_features = pca_features.to(device)  # PCA featureê°€ ìˆë‹¤ë©´ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ\n",
    "            emotion_labels = emotion_labels.to(device)\n",
    "            situation_labels = situation_labels.to(device)\n",
    "\n",
    "            # ëª¨ë¸ì— ì…ë ¥\n",
    "            emotion_logits, situation_logits = model(input_ids, attention_mask, token_type_ids, persona_id, emotion_id, pca_features)\n",
    "\n",
    "            # ì†ì‹¤ ê³„ì‚°\n",
    "            loss = loss_fn(emotion_logits, emotion_labels) + loss_fn(situation_logits, situation_labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # ì˜ˆì¸¡ê°’ ì–»ê¸°\n",
    "            emotion_pred = torch.argmax(emotion_logits, dim=1)\n",
    "            situation_pred = torch.argmax(situation_logits, dim=1)\n",
    "\n",
    "            # ì •í™•ë„ ê³„ì‚°\n",
    "            correct_emotion += (emotion_pred == emotion_labels).sum().item()\n",
    "            correct_situation += (situation_pred == situation_labels).sum().item()\n",
    "\n",
    "            total_emotion += emotion_labels.size(0)\n",
    "            total_situation += situation_labels.size(0)\n",
    "\n",
    "            # ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ì €ì¥\n",
    "            all_emotion_preds.extend(emotion_pred.cpu().numpy())\n",
    "            all_situation_preds.extend(situation_pred.cpu().numpy())\n",
    "            all_emotion_labels.extend(emotion_labels.cpu().numpy())\n",
    "            all_situation_labels.extend(situation_labels.cpu().numpy())\n",
    "\n",
    "    # í‰ê·  ì†ì‹¤ ê³„ì‚°\n",
    "    avg_loss = total_loss / len(test_dataloader)\n",
    "\n",
    "    # ê°ì •ê³¼ ìƒí™© ì •í™•ë„ ê³„ì‚°\n",
    "    emotion_accuracy = correct_emotion / total_emotion\n",
    "    situation_accuracy = correct_situation / total_situation\n",
    "\n",
    "    # F1-Score ê³„ì‚° (ê°ì •, ìƒí™©)\n",
    "    emotion_f1 = f1_score(all_emotion_labels, all_emotion_preds, average='weighted')\n",
    "    situation_f1 = f1_score(all_situation_labels, all_situation_preds, average='weighted')\n",
    "\n",
    "    # Exact Match ê³„ì‚°\n",
    "    emotion_exact_match = (emotion_encoder.inverse_transform(all_emotion_labels) == emotion_encoder.inverse_transform(all_emotion_preds)).mean()\n",
    "    situation_exact_match = (situation_encoder.inverse_transform(all_situation_labels) == situation_encoder.inverse_transform(all_situation_preds)).mean()\n",
    "\n",
    "    return avg_loss, emotion_accuracy, situation_accuracy, emotion_f1, situation_f1, emotion_exact_match, situation_exact_match\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model_name = \"monologg/kobert\"  # KoBERT ëª¨ë¸ëª…\n",
    "num_emotions = len(final_df[\"emotion\"].unique())  # ê°ì • í´ë˜ìŠ¤ ê°œìˆ˜\n",
    "num_situations = len(final_df[\"situation\"].unique())  # ìƒí™© í´ë˜ìŠ¤ ê°œìˆ˜\n",
    "model = KoBERTMultiOutputWithEmbedding(model_name, num_emotions, num_situations, num_personas, num_emotion_ids)\n",
    "\n",
    "# device ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# best_model.pth ë¡œë“œ\n",
    "model.load_state_dict(torch.load(\"kobert_emotion_situation/best_model.pth\"))\n",
    "model.to(device)\n",
    "\n",
    "# í‰ê°€\n",
    "test_loss, emotion_accuracy, situation_accuracy, emotion_f1, situation_f1, emotion_exact_match, situation_exact_match = evaluate_model(\n",
    "    model, test_dataloader, nn.CrossEntropyLoss(), device, emotion_encoder, situation_encoder\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"âœ… Test Loss: {test_loss:.4f}\")\n",
    "print(f\"âœ… Emotion Accuracy: {emotion_accuracy:.4f}\")\n",
    "print(f\"âœ… Situation Accuracy: {situation_accuracy:.4f}\")\n",
    "print(f\"âœ… Emotion F1-Score: {emotion_f1:.4f}\")\n",
    "print(f\"âœ… Situation F1-Score: {situation_f1:.4f}\")\n",
    "print(f\"âœ… Emotion Exact Match: {emotion_exact_match:.4f}\")\n",
    "print(f\"âœ… Situation Exact Match: {situation_exact_match:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa0e1c8-769b-4c1b-9546-977f7beddaf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e335fb31-205a-42b7-b886-4b1a0a3b8002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a44901-b63a-4f57-b202-dcf683e2979e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
