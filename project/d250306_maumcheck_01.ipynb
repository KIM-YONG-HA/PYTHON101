{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b55b227e-1766-4bc9-9c77-3a7a7b4669d6",
   "metadata": {},
   "source": [
    "## 1. json to csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57789958-bb32-43f5-a8eb-06a72212751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 변환 완료: data/train_dataset.csv\n",
      "✅ 변환 완료: data/test_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def convert_json_to_csv(json_file_path, output_csv_path):\n",
    "    \"\"\"\n",
    "    JSON 데이터를 로드하여 DataFrame으로 변환 후 CSV 파일로 저장하는 함수.\n",
    "    \n",
    "    Parameters:\n",
    "        json_file_path (str): JSON 파일 경로\n",
    "        output_csv_path (str): 저장할 CSV 파일 경로\n",
    "    \"\"\"\n",
    "    # JSON 파일 로드\n",
    "    with open(json_file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    # DataFrame 변환\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # 상담 텍스트(HS01, HS02, HS03만 합침) 추출\n",
    "    df[\"text\"] = df[\"talk\"].apply(lambda x: \" \".join([x[\"content\"].get(k, \"\") for k in [\"HS01\", \"HS02\", \"HS03\"]]).strip())\n",
    "\n",
    "    # 감정(E10~E69), 상황(S01~S13), 질병(D01~D02) 레이블 추출\n",
    "    df[\"emotion\"] = df[\"profile\"].apply(lambda x: x[\"emotion\"][\"type\"])  # 감정 ID (E10~E69)\n",
    "    df[\"situation\"] = df[\"profile\"].apply(lambda x: x[\"emotion\"][\"situation\"][0])  # 상황 ID (S01~S13)\n",
    "    df[\"disease\"] = df[\"profile\"].apply(lambda x: x[\"emotion\"][\"situation\"][1] if len(x[\"emotion\"][\"situation\"]) > 1 else \"D02\")  # 질병 ID (D01 or D02)\n",
    "\n",
    "    # 필요 없는 컬럼 제거\n",
    "    df = df[[\"text\", \"emotion\", \"situation\", \"disease\"]]\n",
    "\n",
    "    # CSV 저장\n",
    "    df.to_csv(output_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "    print(f\"🙏 변환 완료: {output_csv_path}\")\n",
    "\n",
    "# 🔹 두 개의 JSON 파일 변환 실행\n",
    "convert_json_to_csv(\"data/감성대화말뭉치(최종데이터)_Training.json\", \"data/train_dataset.csv\")\n",
    "convert_json_to_csv(\"data/감성대화말뭉치(최종데이터)_Validation.json\", \"data/test_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eb8f23-0fe4-47c4-bb3e-97d1db668454",
   "metadata": {},
   "source": [
    "## 2. 데이터프레임 샘플 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ce4dc7a-f877-44c7-9ec9-e6f036b7facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train_dataset.csv')\n",
    "test_df = pd.read_csv('data/test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "daecd167-0319-4dc8-913d-98d2525088a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text emotion situation disease\n",
      "0  일은 왜 해도 해도 끝이 없을까? 화가 난다. 그냥 내가 해결하는 게 나아. 남들한...     E18       S06     D02\n",
      "1  이번 달에 또 급여가 깎였어! 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나....     E18       S06     D02\n",
      "2  회사에 신입이 들어왔는데 말투가 거슬려. 그런 애를 매일 봐야 한다고 생각하니까 스...     E18       S06     D02\n",
      "3  직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜. 일도 많은 데 정말 분하고 ...     E18       S06     D02\n",
      "4  얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나. 상사인 나에게 ...     E18       S06     D02\n",
      "                                                text emotion situation disease\n",
      "0  이번 프로젝트에서 발표를 하는데 내가 실수하는 바람에 우리 팀이 감점을 받았어. 너...     E31       S06     D02\n",
      "1  회사에서 중요한 프로젝트를 혼자 하게 됐는데 솔직히 두렵고 무서워. 나에게 너무 크...     E31       S06     D02\n",
      "2  상사가 너무 무섭게 생겨서 친해지는 게 너무 두려워. 무섭게 생겼는데도 업무를 보려...     E31       S06     D02\n",
      "3  이번에 힘들게 들어간 첫 직장이거든. 첫 직장이라서 그런지 너무 긴장된다. 첫 직장...     E31       S06     D02\n",
      "4  직장에서 동료들이랑 관계가 안 좋아질까 봐 걱정돼. 내가 낯가림이 심해서 친해질 수...     E31       S06     D02\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f94b220-626b-4c89-9697-3daecffc860e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51628 entries, 0 to 51627\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       51628 non-null  object\n",
      " 1   emotion    51628 non-null  object\n",
      " 2   situation  51628 non-null  object\n",
      " 3   disease    51628 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.6+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6640 entries, 0 to 6639\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       6640 non-null   object\n",
      " 1   emotion    6640 non-null   object\n",
      " 2   situation  6640 non-null   object\n",
      " 3   disease    6640 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 207.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_df.info())\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0818579-eb63-4498-843e-3c64c6a9513f",
   "metadata": {},
   "source": [
    "## **3. 학습 데이터 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62734301-be28-4bee-9948-6de9fc06b27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def preprocess_dataset(df, output_csv_path=None):\n",
    "    \"\"\"\n",
    "    데이터프레임을 전처리하는 함수 (특수문자 제거 및 ID 매핑)\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): 전처리할 데이터프레임\n",
    "        output_csv_path (str, optional): 저장할 CSV 파일 경로 (기본값: None)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 전처리된 데이터프레임\n",
    "    \"\"\"\n",
    "    # 🔹 (1) 텍스트 정제: 특수문자 제거 및 공백 정리\n",
    "    def clean_text(text):\n",
    "        text = re.sub(r\"[^가-힣a-zA-Z0-9\\s]\", \"\", text)  # 한글, 영문, 숫자, 공백 제외 삭제\n",
    "        text = re.sub(r\"\\s+\", \" \", text).strip()  # 연속된 공백 제거\n",
    "        return text\n",
    "\n",
    "    df[\"text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "    # 🔹 (2) 감정, 상황, 질병 ID를 숫자로 변환\n",
    "    emotion_mapping = {e: idx for idx, e in enumerate(sorted(df[\"emotion\"].unique()))}\n",
    "    situation_mapping = {s: idx for idx, s in enumerate(sorted(df[\"situation\"].unique()))}\n",
    "    disease_mapping = {\"D01\": 0, \"D02\": 1}  # 질병 여부를 0/1로 변환\n",
    "\n",
    "    # 🔹 (3) 매핑 적용\n",
    "    df[\"emotion\"] = df[\"emotion\"].map(emotion_mapping)\n",
    "    df[\"situation\"] = df[\"situation\"].map(situation_mapping)\n",
    "    df[\"disease\"] = df[\"disease\"].map(disease_mapping)\n",
    "\n",
    "    # 🔹 (4) CSV 저장 (옵션)\n",
    "    if output_csv_path:\n",
    "        df.to_csv(output_csv_path, index=False, encoding=\"utf-8-sig\")\n",
    "        print(f\"🙏 데이터 전처리 완료: {output_csv_path}\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52d4e4a0-9199-45b0-8fae-ea8807044872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🙏 데이터 전처리 완료: data/pre_train_dataset.csv\n",
      "🙏 데이터 전처리 완료: data/pre_test_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "train_df = pd.read_csv(\"data/train_dataset.csv\")\n",
    "test_df = pd.read_csv(\"data/test_dataset.csv\")\n",
    "\n",
    "# 전처리 실행 및 CSV 저장\n",
    "pre_train_df = preprocess_dataset(train_df, \"data/pre_train_dataset.csv\")\n",
    "pre_test_df = preprocess_dataset(test_df, \"data/pre_test_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ced209a-3f3f-4c72-80c5-fdaf40775f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>situation</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>일은 왜 해도 해도 끝이 없을까 화가 난다 그냥 내가 해결하는 게 나아 남들한테 부...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이번 달에 또 급여가 깎였어 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나 최...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>회사에 신입이 들어왔는데 말투가 거슬려 그런 애를 매일 봐야 한다고 생각하니까 스트...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜 일도 많은 데 정말 분하고 섭...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나 상사인 나에게 먼...</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion  situation  \\\n",
       "0  일은 왜 해도 해도 끝이 없을까 화가 난다 그냥 내가 해결하는 게 나아 남들한테 부...        8          5   \n",
       "1  이번 달에 또 급여가 깎였어 물가는 오르는데 월급만 자꾸 깎이니까 너무 화가 나 최...        8          5   \n",
       "2  회사에 신입이 들어왔는데 말투가 거슬려 그런 애를 매일 봐야 한다고 생각하니까 스트...        8          5   \n",
       "3  직장에서 막내라는 이유로 나에게만 온갖 심부름을 시켜 일도 많은 데 정말 분하고 섭...        8          5   \n",
       "4  얼마 전 입사한 신입사원이 나를 무시하는 것 같아서 너무 화가 나 상사인 나에게 먼...        8          5   \n",
       "\n",
       "   disease  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7471ed2-acbb-4f7b-add5-23bd19a4d86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51628 entries, 0 to 51627\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       51628 non-null  object\n",
      " 1   emotion    51628 non-null  int64 \n",
      " 2   situation  51628 non-null  int64 \n",
      " 3   disease    51628 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "pre_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "52065126-b260-4636-bdaf-19e8767d05ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e360934fa049fb893a7a4fa913e1e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/263 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kj\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\kj\\.cache\\huggingface\\hub\\models--monologg--kobert. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45eca99bb2184e469abdb04a000ee4e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/77.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'KoBertTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b9d0c6b9724e7d8eaa7fb1c706aa6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/426 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0d6c1c2772453ea8dfdaff4e97f251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/369M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 배치 데이터 샘플 확인:\n",
      "input_ids 크기: torch.Size([16, 64])\n",
      "attention_mask 크기: torch.Size([16, 64])\n",
      "labels_emotion 크기: torch.Size([16])\n",
      "labels_situation 크기: torch.Size([16])\n",
      "labels_disease 크기: torch.Size([16])\n",
      "✅ Huggingface KoBERT 토큰화 및 데이터 준비 완료\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv(\"data/pre_train_dataset.csv\")\n",
    "\n",
    "# 🔹 (1) Huggingface KoBERT 모델 & 토크나이저 불러오기\n",
    "model_name = \"monologg/kobert\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "kobert_model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# 🔹 (2) 토큰화 함수 정의\n",
    "def tokenize_text(text):\n",
    "    encoded = tokenizer.encode_plus(\n",
    "        text,\n",
    "        max_length=64,  # 최대 64토큰까지 사용\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"  # PyTorch Tensor 형식으로 반환\n",
    "    )\n",
    "    return encoded[\"input_ids\"], encoded[\"attention_mask\"]\n",
    "\n",
    "\n",
    "\n",
    "# 🔹 (3) 데이터셋 클래스 정의\n",
    "class EmotionDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.texts = dataframe[\"text\"].tolist()\n",
    "        self.emotions = dataframe[\"emotion\"].tolist()\n",
    "        self.situations = dataframe[\"situation\"].tolist()\n",
    "        self.diseases = dataframe[\"disease\"].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    # def __getitem__(self, idx):\n",
    "    #     input_ids, attention_mask = tokenize_text(self.texts[idx])\n",
    "    #     emotion_label = torch.tensor(self.emotions[idx], dtype=torch.long)\n",
    "    #     situation_label = torch.tensor(self.situations[idx], dtype=torch.long)\n",
    "    #     disease_label = torch.tensor(self.diseases[idx], dtype=torch.long)\n",
    "    #     return input_ids, attention_mask, emotion_label, situation_label, disease_label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids, attention_mask = tokenize_text(self.texts[idx])\n",
    "        return {\n",
    "            \"input_ids\": input_ids.squeeze(0),\n",
    "            \"attention_mask\": attention_mask.squeeze(0),\n",
    "            \"labels_emotion\": torch.tensor(self.emotions[idx], dtype=torch.long),\n",
    "            \"labels_situation\": torch.tensor(self.situations[idx], dtype=torch.long),\n",
    "            \"labels_disease\": torch.tensor(self.diseases[idx], dtype=torch.long),\n",
    "        }\n",
    "\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "train_dataset = EmotionDataset(df)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# 첫 번째 배치 데이터 확인\n",
    "for batch in train_loader:\n",
    "    print(\"🔹 배치 데이터 샘플 확인:\")\n",
    "    print(f\"input_ids 크기: {batch['input_ids'].shape}\")\n",
    "    print(f\"attention_mask 크기: {batch['attention_mask'].shape}\")\n",
    "    print(f\"labels_emotion 크기: {batch['labels_emotion'].shape}\")\n",
    "    print(f\"labels_situation 크기: {batch['labels_situation'].shape}\")\n",
    "    print(f\"labels_disease 크기: {batch['labels_disease'].shape}\")\n",
    "    break  # 첫 번째 배치만 확인\n",
    "\n",
    "\n",
    "print(\"✅ Huggingface KoBERT 토큰화 및 데이터 준비 완료\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
