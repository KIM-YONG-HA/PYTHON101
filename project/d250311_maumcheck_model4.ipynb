{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c6fc965-ca47-46d7-a489-09e135cce68e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu118\n",
      "True\n",
      "11.8\n",
      "NVIDIA GeForce RTX 3050\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())  # CUDAê°€ í™œì„±í™” ì—¬ë¶€\n",
    "print(torch.version.cuda)  # ì„¤ì¹˜ëœ CUDA ë²„ì „ ì¶œë ¥\n",
    "print(torch.cuda.get_device_name(0))  # ì‚¬ìš© ì¤‘ì¸ GPU\n",
    "print(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0411ec3-f8c6-47d9-8ccd-883e0e522592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('data/train_dataset.csv')\n",
    "test_df = pd.read_csv('data/test_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "739ed61f-7382-403e-8bb5-7c41a8ebcc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text emotion situation\n",
      "0  ì¼ì€ ì™œ í•´ë„ í•´ë„ ëì´ ì—†ì„ê¹Œ? í™”ê°€ ë‚œë‹¤. ê·¸ëƒ¥ ë‚´ê°€ í•´ê²°í•˜ëŠ” ê²Œ ë‚˜ì•„. ë‚¨ë“¤í•œ...     E18       S06\n",
      "1  ì´ë²ˆ ë‹¬ì— ë˜ ê¸‰ì—¬ê°€ ê¹ì˜€ì–´! ë¬¼ê°€ëŠ” ì˜¤ë¥´ëŠ”ë° ì›”ê¸‰ë§Œ ìê¾¸ ê¹ì´ë‹ˆê¹Œ ë„ˆë¬´ í™”ê°€ ë‚˜....     E18       S06\n",
      "2  íšŒì‚¬ì— ì‹ ì…ì´ ë“¤ì–´ì™”ëŠ”ë° ë§íˆ¬ê°€ ê±°ìŠ¬ë ¤. ê·¸ëŸ° ì• ë¥¼ ë§¤ì¼ ë´ì•¼ í•œë‹¤ê³  ìƒê°í•˜ë‹ˆê¹Œ ìŠ¤...     E18       S06\n",
      "3  ì§ì¥ì—ì„œ ë§‰ë‚´ë¼ëŠ” ì´ìœ ë¡œ ë‚˜ì—ê²Œë§Œ ì˜¨ê°– ì‹¬ë¶€ë¦„ì„ ì‹œì¼œ. ì¼ë„ ë§ì€ ë° ì •ë§ ë¶„í•˜ê³  ...     E18       S06\n",
      "4  ì–¼ë§ˆ ì „ ì…ì‚¬í•œ ì‹ ì…ì‚¬ì›ì´ ë‚˜ë¥¼ ë¬´ì‹œí•˜ëŠ” ê²ƒ ê°™ì•„ì„œ ë„ˆë¬´ í™”ê°€ ë‚˜. ìƒì‚¬ì¸ ë‚˜ì—ê²Œ ...     E18       S06\n",
      "                                                text emotion situation\n",
      "0  ì´ë²ˆ í”„ë¡œì íŠ¸ì—ì„œ ë°œí‘œë¥¼ í•˜ëŠ”ë° ë‚´ê°€ ì‹¤ìˆ˜í•˜ëŠ” ë°”ëŒì— ìš°ë¦¬ íŒ€ì´ ê°ì ì„ ë°›ì•˜ì–´. ë„ˆ...     E31       S06\n",
      "1  íšŒì‚¬ì—ì„œ ì¤‘ìš”í•œ í”„ë¡œì íŠ¸ë¥¼ í˜¼ì í•˜ê²Œ ëëŠ”ë° ì†”ì§íˆ ë‘ë µê³  ë¬´ì„œì›Œ. ë‚˜ì—ê²Œ ë„ˆë¬´ í¬...     E31       S06\n",
      "2  ìƒì‚¬ê°€ ë„ˆë¬´ ë¬´ì„­ê²Œ ìƒê²¨ì„œ ì¹œí•´ì§€ëŠ” ê²Œ ë„ˆë¬´ ë‘ë ¤ì›Œ. ë¬´ì„­ê²Œ ìƒê²¼ëŠ”ë°ë„ ì—…ë¬´ë¥¼ ë³´ë ¤...     E31       S06\n",
      "3  ì´ë²ˆì— í˜ë“¤ê²Œ ë“¤ì–´ê°„ ì²« ì§ì¥ì´ê±°ë“ . ì²« ì§ì¥ì´ë¼ì„œ ê·¸ëŸ°ì§€ ë„ˆë¬´ ê¸´ì¥ëœë‹¤. ì²« ì§ì¥...     E31       S06\n",
      "4  ì§ì¥ì—ì„œ ë™ë£Œë“¤ì´ë‘ ê´€ê³„ê°€ ì•ˆ ì¢‹ì•„ì§ˆê¹Œ ë´ ê±±ì •ë¼. ë‚´ê°€ ë‚¯ê°€ë¦¼ì´ ì‹¬í•´ì„œ ì¹œí•´ì§ˆ ìˆ˜...     E31       S06\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd70f052-fbc1-498a-8dc0-92be2607d64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51628 entries, 0 to 51627\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       51628 non-null  object\n",
      " 1   emotion    51628 non-null  object\n",
      " 2   situation  51628 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.2+ MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6640 entries, 0 to 6639\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   text       6640 non-null   object\n",
      " 1   emotion    6640 non-null   object\n",
      " 2   situation  6640 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 155.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_df.info())\n",
    "print(test_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "12b33529-4272-4823-9563-39e0b0115f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì¼ì€ ì™œ í•´ë„ í•´ë„ ëì´ ì—†ì„ê¹Œ? í™”ê°€ ë‚œë‹¤. ê·¸ëƒ¥ ë‚´ê°€ í•´ê²°í•˜ëŠ” ê²Œ ë‚˜ì•„. ë‚¨ë“¤í•œí…Œ ë¶€ë‹´ ì£¼ê³  ì‹¶ì§€ë„ ì•Šê³ .'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d6c80f3-2168-4024-979c-c090c6fe4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# í•œêµ­ì–´ ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "url = \"https://raw.githubusercontent.com/stopwords-iso/stopwords-ko/master/stopwords-ko.txt\"\n",
    "response = requests.get(url)\n",
    "korean_stopwords = set(response.text.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "40a4b01a-a6d2-4a04-83dd-c30c6638c5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_with_adverbs_and_verbs(text):\n",
    "    # í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°\n",
    "    if not isinstance(text, str):  \n",
    "        return \"\"\n",
    "    \n",
    "    parsed_text = mecab.parse(text).split(\"\\n\")[:-2]  # ë§ˆì§€ë§‰ ì¤„(EOS, ê³µë°±) ì œê±°\n",
    "    tokens = [line.split(\"\\t\") for line in parsed_text if \"\\t\" in line]\n",
    "    \n",
    "    # í’ˆì‚¬ í•„í„°ë§ (ëª…ì‚¬, í˜•ìš©ì‚¬, ë¶€ì‚¬ë§Œ ë‚¨ê¸°ê¸°)\n",
    "    keywords = []\n",
    "    for token in tokens:\n",
    "        if len(token) < 2:\n",
    "            continue\n",
    "        word, features = token[0], token[1].split(\",\")\n",
    "        tag = features[0]  \n",
    "        lemma = features[-3]  # ì›í˜•ì„ ì¶”ì¶œ\n",
    "\n",
    "        # ëª…ì‚¬(NNG, NNP) ê·¸ëŒ€ë¡œ ì¶”ê°€\n",
    "        if tag in ['NNG', 'NNP']:\n",
    "            keywords.append(word)\n",
    "\n",
    "        # í˜•ìš©ì‚¬(VA) ì›í˜• ë³€í™˜ ë° ì¶”ê°€\n",
    "        elif tag == 'VA':\n",
    "            if lemma != '*' and lemma != '' and lemma != word:\n",
    "                keywords.append(lemma)\n",
    "            else:\n",
    "                keywords.append(word + \"ë‹¤\")\n",
    "\n",
    "        # ë¶€ì‚¬(MAG)ëŠ” ê°ì •ì˜ ê°•ë„ë‚˜ ìƒíƒœë¥¼ ê°•ì¡°í•˜ë¯€ë¡œ ì¶”ê°€\n",
    "        elif tag == 'MAG':  # ë¶€ì‚¬ íƒœê·¸\n",
    "            keywords.append(word)\n",
    "\n",
    "    # ì¤‘ë³µ ë‹¨ì–´ ì œê±° & ë¶ˆìš©ì–´ ì œê±°\n",
    "    keywords = list(dict.fromkeys(keywords))  # ì¤‘ë³µ ì œê±°\n",
    "    keywords = [word for word in keywords if word not in stopwords and len(word) > 1]  # ë¶ˆìš©ì–´ ì œê±°\n",
    "    \n",
    "    return \" \".join(keywords)\n",
    "\n",
    "# MeCab ì ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
    "train_df['text'] = train_df['text'].apply(preprocess_text_with_adverbs_and_verbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "20e90f66-2c13-4cf4-97a5-9c1804c59466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               text emotion situation\n",
      "0                       ì—†ë‹¤ ê·¸ëƒ¥ í•´ê²° ë¶€ë‹´     E18       S06\n",
      "1    ê¸‰ì—¬ ë¬¼ê°€ ì›”ê¸‰ ìê¾¸ ë„ˆë¬´ ìµœëŒ€í•œ ì§€ì¶œ ì–µì œ ê³ ì • ì—†ë‹¤     E18       S06\n",
      "2  íšŒì‚¬ ì‹ ì… ë§íˆ¬ ë§¤ì¼ ìƒê° ìŠ¤íŠ¸ë ˆìŠ¤ ì‚¬ëŒ ì–µì§€ë¡œ ê±°ë¦¬ ì˜ˆì˜     E18       S06\n",
      "3  ì§ì¥ ë§‰ë‚´ ì´ìœ  ì‹¬ë¶€ë¦„ ë§ë‹¤ ì •ë§ ë¶„í•˜ë‹¤ ì‚¬ëŒ ì´ì•¼ê¸° ë°©í•´     E18       S06\n",
      "4        ì…ì‚¬ ì‹ ì… ì‚¬ì› ë¬´ì‹œ ë„ˆë¬´ ìƒì‚¬ ë¨¼ì € ì¸ì‚¬ ë§¤ì¼     E18       S06\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b7c8a-247f-42e3-bcbf-95d7431b6347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2d0dbae-db21-44bf-81f2-b7e6789f55b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# print(len(train_df['emotion'].unique()), \"ê°œ\", end='\\n\\n')\n",
    "# print(train_df['emotion'].value_counts().max())\n",
    "# print(train_df['emotion'].value_counts().min())\n",
    "# print((train_df['emotion'].value_counts().max()-train_df['emotion'].value_counts().min())/60)\n",
    "# print(train_df['emotion'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d7057ba-c015-4584-9e3f-ff3c5773d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(train_df['situation'].unique()), \"ê°œ\", end='\\n\\n')\n",
    "# print(train_df['situation'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "997a1355-b707-4494-bdb5-5f1ea028da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Create a figure and axes for two vertical subplots\n",
    "# fig, axes = plt.subplots(2, 1, figsize=(14, 14))\n",
    "\n",
    "# # Emotion distribution bar chart\n",
    "# axes[0].bar(train_df['emotion'].value_counts().index, train_df['emotion'].value_counts().values, color='skyblue', edgecolor='black')\n",
    "# axes[0].set_title('Emotion Distribution')\n",
    "# axes[0].set_xlabel('Emotion')\n",
    "# axes[0].set_ylabel('Count')\n",
    "# axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# # Situation distribution bar chart\n",
    "# axes[1].bar(train_df['situation'].value_counts().index, train_df['situation'].value_counts().values, color='salmon', edgecolor='black')\n",
    "# axes[1].set_title('Situation Distribution')\n",
    "# axes[1].set_xlabel('Situation')\n",
    "# axes[1].set_ylabel('Count')\n",
    "# axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# plt.tight_layout(pad=4.0)  # Adjust layout and padding for better label placement\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "011d4d76-a532-43b1-b512-ccb964ac7ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"[^ê°€-í£a-zA-Z0-9\\s]\", \"\", text)  # í•œê¸€, ì˜ì–´, ìˆ«ì, ê³µë°±ë§Œ ìœ ì§€\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # ì¤‘ë³µ ê³µë°± ì œê±°\n",
    "    return text\n",
    "\n",
    "train_df[\"text\"] = train_df[\"text\"].apply(clean_text)\n",
    "test_df[\"text\"] = test_df[\"text\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d3fa20b7-bbe4-47fa-9ea4-57f2b5690662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>situation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ì—†ë‹¤ ê·¸ëƒ¥ í•´ê²° ë¶€ë‹´</td>\n",
       "      <td>E18</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ê¸‰ì—¬ ë¬¼ê°€ ì›”ê¸‰ ìê¾¸ ë„ˆë¬´ ìµœëŒ€í•œ ì§€ì¶œ ì–µì œ ê³ ì • ì—†ë‹¤</td>\n",
       "      <td>E18</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>íšŒì‚¬ ì‹ ì… ë§íˆ¬ ë§¤ì¼ ìƒê° ìŠ¤íŠ¸ë ˆìŠ¤ ì‚¬ëŒ ì–µì§€ë¡œ ê±°ë¦¬ ì˜ˆì˜</td>\n",
       "      <td>E18</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ì§ì¥ ë§‰ë‚´ ì´ìœ  ì‹¬ë¶€ë¦„ ë§ë‹¤ ì •ë§ ë¶„í•˜ë‹¤ ì‚¬ëŒ ì´ì•¼ê¸° ë°©í•´</td>\n",
       "      <td>E18</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ì…ì‚¬ ì‹ ì… ì‚¬ì› ë¬´ì‹œ ë„ˆë¬´ ìƒì‚¬ ë¨¼ì € ì¸ì‚¬ ë§¤ì¼</td>\n",
       "      <td>E18</td>\n",
       "      <td>S06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               text emotion situation\n",
       "0                       ì—†ë‹¤ ê·¸ëƒ¥ í•´ê²° ë¶€ë‹´     E18       S06\n",
       "1    ê¸‰ì—¬ ë¬¼ê°€ ì›”ê¸‰ ìê¾¸ ë„ˆë¬´ ìµœëŒ€í•œ ì§€ì¶œ ì–µì œ ê³ ì • ì—†ë‹¤     E18       S06\n",
       "2  íšŒì‚¬ ì‹ ì… ë§íˆ¬ ë§¤ì¼ ìƒê° ìŠ¤íŠ¸ë ˆìŠ¤ ì‚¬ëŒ ì–µì§€ë¡œ ê±°ë¦¬ ì˜ˆì˜     E18       S06\n",
       "3  ì§ì¥ ë§‰ë‚´ ì´ìœ  ì‹¬ë¶€ë¦„ ë§ë‹¤ ì •ë§ ë¶„í•˜ë‹¤ ì‚¬ëŒ ì´ì•¼ê¸° ë°©í•´     E18       S06\n",
       "4        ì…ì‚¬ ì‹ ì… ì‚¬ì› ë¬´ì‹œ ë„ˆë¬´ ìƒì‚¬ ë¨¼ì € ì¸ì‚¬ ë§¤ì¼     E18       S06"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6139a0fb-ff88-4343-93c4-311238920b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì—†ë‹¤ ê·¸ëƒ¥ í•´ê²° ë¶€ë‹´'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6583a56e-ed83-4570-9f15-752f7068aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ê°ì • ë¼ë²¨ ì¸ì½”ë”©\n",
    "emotion_encoder = LabelEncoder()\n",
    "train_df[\"emotion\"] = emotion_encoder.fit_transform(train_df[\"emotion\"])\n",
    "test_df[\"emotion\"] = emotion_encoder.transform(test_df[\"emotion\"])\n",
    "\n",
    "# ìƒí™© ë¼ë²¨ ì¸ì½”ë”©\n",
    "situation_encoder = LabelEncoder()\n",
    "train_df[\"situation\"] = situation_encoder.fit_transform(train_df[\"situation\"])\n",
    "test_df[\"situation\"] = situation_encoder.transform(test_df[\"situation\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "dbcdf34a-3fb5-42ad-b1e8-c1fd059ba66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>situation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ì—†ë‹¤ ê·¸ëƒ¥ í•´ê²° ë¶€ë‹´</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ê¸‰ì—¬ ë¬¼ê°€ ì›”ê¸‰ ìê¾¸ ë„ˆë¬´ ìµœëŒ€í•œ ì§€ì¶œ ì–µì œ ê³ ì • ì—†ë‹¤</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>íšŒì‚¬ ì‹ ì… ë§íˆ¬ ë§¤ì¼ ìƒê° ìŠ¤íŠ¸ë ˆìŠ¤ ì‚¬ëŒ ì–µì§€ë¡œ ê±°ë¦¬ ì˜ˆì˜</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ì§ì¥ ë§‰ë‚´ ì´ìœ  ì‹¬ë¶€ë¦„ ë§ë‹¤ ì •ë§ ë¶„í•˜ë‹¤ ì‚¬ëŒ ì´ì•¼ê¸° ë°©í•´</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ì…ì‚¬ ì‹ ì… ì‚¬ì› ë¬´ì‹œ ë„ˆë¬´ ìƒì‚¬ ë¨¼ì € ì¸ì‚¬ ë§¤ì¼</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               text  emotion  situation\n",
       "0                       ì—†ë‹¤ ê·¸ëƒ¥ í•´ê²° ë¶€ë‹´        8          5\n",
       "1    ê¸‰ì—¬ ë¬¼ê°€ ì›”ê¸‰ ìê¾¸ ë„ˆë¬´ ìµœëŒ€í•œ ì§€ì¶œ ì–µì œ ê³ ì • ì—†ë‹¤        8          5\n",
       "2  íšŒì‚¬ ì‹ ì… ë§íˆ¬ ë§¤ì¼ ìƒê° ìŠ¤íŠ¸ë ˆìŠ¤ ì‚¬ëŒ ì–µì§€ë¡œ ê±°ë¦¬ ì˜ˆì˜        8          5\n",
       "3  ì§ì¥ ë§‰ë‚´ ì´ìœ  ì‹¬ë¶€ë¦„ ë§ë‹¤ ì •ë§ ë¶„í•˜ë‹¤ ì‚¬ëŒ ì´ì•¼ê¸° ë°©í•´        8          5\n",
       "4        ì…ì‚¬ ì‹ ì… ì‚¬ì› ë¬´ì‹œ ë„ˆë¬´ ìƒì‚¬ ë¨¼ì € ì¸ì‚¬ ë§¤ì¼        8          5"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f27276bf-5b0b-4bfd-96eb-b3df44990190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel, AutoTokenizer\n",
    "\n",
    "# âœ… 1. KoBERT ì»¤ìŠ¤í…€ ëª¨ë¸ ì •ì˜ (ê°ì • + ìƒí™© ë‹¤ì¤‘ ë¶„ë¥˜)\n",
    "class KoBERTMultiOutput(nn.Module):\n",
    "    def __init__(self, model_name, num_emotions, num_situations):\n",
    "        super(KoBERTMultiOutput, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)  # KoBERT ê¸°ë³¸ ëª¨ë¸\n",
    "        self.dropout = nn.Dropout(0.1)  # ë“œë¡­ì•„ì›ƒ ë ˆì´ì–´ ì¶”ê°€\n",
    "        self.emotion_classifier = nn.Linear(self.bert.config.hidden_size, num_emotions)  # ê°ì • ë¶„ë¥˜ê¸°\n",
    "        self.situation_classifier = nn.Linear(self.bert.config.hidden_size, num_situations)  # ìƒí™© ë¶„ë¥˜ê¸°\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        # Bert ëª¨ë¸ì„ í†µí•´ ì¶œë ¥ê°’ì„ ì–»ìŒ\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        pooled_output = self.dropout(outputs.pooler_output)  # BERT ì¶œë ¥ì—ì„œ poolingëœ ë²¡í„°ì— ë“œë¡­ì•„ì›ƒ ì ìš©\n",
    "\n",
    "        # ê°ì •ê³¼ ìƒí™©ì„ ìœ„í•œ ë¡œì§“ ë¶„ë¦¬\n",
    "        emotion_logits = self.emotion_classifier(pooled_output)\n",
    "        situation_logits = self.situation_classifier(pooled_output)\n",
    "\n",
    "        # ë‘ ê°€ì§€ ë¡œì§“ ë°˜í™˜\n",
    "        return emotion_logits, situation_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fa0329f2-5dd1-41a3-9625-92113dcfe30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[   2,  806, 5156, 1458, 1632, 1786, 6273, 6003, 7318, 3742,    3,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2, 4627, 4949, 4872,  517, 6189, 7431, 7096, 3273, 2267, 5468, 2734,\n",
      "         6542,  517, 7095, 5731,    3,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2, 1423, 4627, 4396, 7316, 1437,  950, 4206, 3273, 3756, 3343,    3,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2, 4604, 1458, 3774, 3055, 2584, 4455, 3673, 3273, 2063, 3891, 2406,\n",
      "         1951, 5156, 3220, 7774,    3,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2, 3257, 4996, 3273, 3673,  517, 5330, 5663, 1917, 3114, 1951, 4206,\n",
      "         1042, 3367, 1370, 7295, 4355, 4598, 7342, 1956,    3,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2, 3042, 4998, 5439,  972, 4212, 7408, 5341, 4847,  993, 6542, 1425,\n",
      "         2986, 1585, 5563, 3673, 3647, 5812, 3273,    3,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2, 1680, 3742, 5176, 7953,  993, 5944, 5491, 1254, 1429, 5782,  938,\n",
      "         1493, 4249, 4136, 1574,    3,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2, 1996, 4571,  984, 5101, 2474, 2705, 1927, 6527, 1549,    3,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2, 2573, 7467, 5561, 1750,  517, 5330, 5646, 2207, 7846, 2618, 4206,\n",
      "          765, 3219,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2,  517, 5399, 6368, 3437, 6222,  517, 7352, 1951, 1476, 5712, 7482,\n",
      "         1002, 5382,  517, 7219, 5782,  882, 1088, 3367, 2705, 4948, 5808, 1549,\n",
      "         3273, 4229, 1717, 4919, 4083, 5213, 5782, 1174, 7396, 5782, 4722,    3,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2, 1493, 4249, 4103, 1951,  517, 6357, 3273, 3462, 2934, 3140,    3,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2, 3111, 6122, 3514, 4368, 4396, 7316,  807, 6493, 4326, 3367, 4491,\n",
      "         7295, 1192, 3742,  755, 6519, 3006, 5788, 2971,    3,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2, 4206, 4355, 3264, 6527, 3042,  517, 7219, 5782, 3742, 4102,  765,\n",
      "         1659, 2279, 1002,    3,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2, 4299, 4684,  517, 6186, 5782, 1423,  950, 3673, 2618, 4206, 4551,\n",
      "         4223,  765, 3321,    3,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2, 4384, 6498, 3468, 7468, 1113, 3943, 3520, 3897, 4773, 6039, 4212,\n",
      "         7408, 5341, 3891, 3533, 6165, 4102, 3273, 1058, 1076, 4206, 4534,  765,\n",
      "         2149, 6812,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n",
      "        [   2, 1039, 3005, 2433, 1282, 4206, 3039, 5341, 4684, 1961,    3,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1]]), tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), tensor([40,  5,  3, 34, 35, 40,  9, 24, 25, 49,  4,  3, 42, 16,  9, 17]), tensor([ 9,  2,  4,  5,  0, 11, 11,  5,  0,  3,  7,  8, 11,  6, 10,  5])]\n",
      "[tensor([[   2, 3697, 4902,  ...,    1,    1,    1],\n",
      "        [   2, 5156, 6903,  ...,    1,    1,    1],\n",
      "        [   2, 2658, 6494,  ...,    1,    1,    1],\n",
      "        ...,\n",
      "        [   2, 1434, 4627,  ...,    1,    1,    1],\n",
      "        [   2, 1435, 1956,  ...,    1,    1,    1],\n",
      "        [   2, 4627, 5330,  ...,    1,    1,    1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), tensor([21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 15, 15, 15, 15]), tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 2, 2, 2])]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# âœ… 1. Tokenizer ì´ˆê¸°í™”\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"monologg/kobert\",  trust_remote_code=True)  # KoBERT ëª¨ë¸ì— ë§ëŠ” í† í¬ë‚˜ì´ì € ì‚¬ìš©\n",
    "\n",
    "# âœ… 2. train_dfì—ì„œ í…ìŠ¤íŠ¸ë¥¼ í† í°í™” (í›ˆë ¨ ë°ì´í„°)\n",
    "train_texts = train_df[\"text\"].tolist()  # 'text' ì»¬ëŸ¼ì— í›ˆë ¨ ë°ì´í„°ê°€ ìˆë‹¤ê³  ê°€ì •\n",
    "train_encodings = tokenizer(train_texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")  # í† í°í™”\n",
    "\n",
    "# âœ… 3. ë¼ë²¨ ë°ì´í„° (ê°ì •, ìƒí™©)\n",
    "# ê°ì •ê³¼ ìƒí™©ì„ ìˆ«ì ë ˆì´ë¸”ë¡œ ë³€í™˜\n",
    "emotion_encoder = LabelEncoder()\n",
    "situation_encoder = LabelEncoder()\n",
    "\n",
    "emotion_labels = emotion_encoder.fit_transform(train_df['emotion'].values)  # ê°ì • ë¼ë²¨\n",
    "situation_labels = situation_encoder.fit_transform(train_df['situation'].values)  # ìƒí™© ë¼ë²¨\n",
    "\n",
    "# í…ì„œë¡œ ë³€í™˜\n",
    "emotion_labels = torch.tensor(emotion_labels)\n",
    "situation_labels = torch.tensor(situation_labels)\n",
    "\n",
    "# âœ… 4. TensorDataset ìƒì„± (ì…ë ¥ ë°ì´í„°ì™€ ë ˆì´ë¸”ì„ ë¬¶ìŒ)\n",
    "input_ids = train_encodings['input_ids']\n",
    "attention_mask = train_encodings['attention_mask']\n",
    "token_type_ids = train_encodings['token_type_ids'] if 'token_type_ids' in train_encodings else torch.zeros_like(input_ids)\n",
    "\n",
    "# TensorDatasetì„ ì´ìš©í•´ í›ˆë ¨ ë°ì´í„°ì…‹ì„ ìƒì„±\n",
    "train_dataset = TensorDataset(input_ids, attention_mask, token_type_ids, emotion_labels, situation_labels)\n",
    "\n",
    "# âœ… 5. DataLoader ìƒì„± (ë°°ì¹˜ í¬ê¸° ì„¤ì •)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)  # ë°°ì¹˜ í¬ê¸° 16ìœ¼ë¡œ ì„¤ì •\n",
    "\n",
    "\n",
    "# âœ… 6. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±\n",
    "test_texts = test_df[\"text\"].tolist()  # 'text' ì»¬ëŸ¼ì— í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ìˆë‹¤ê³  ê°€ì •\n",
    "test_encodings = tokenizer(test_texts, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")  # í† í°í™”\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¼ë²¨ (ê°ì •, ìƒí™©)\n",
    "emotion_labels_test = emotion_encoder.transform(test_df['emotion'].values)  # ê°ì • ë¼ë²¨\n",
    "situation_labels_test = situation_encoder.transform(test_df['situation'].values)  # ìƒí™© ë¼ë²¨\n",
    "\n",
    "# í…ì„œë¡œ ë³€í™˜\n",
    "emotion_labels_test = torch.tensor(emotion_labels_test)\n",
    "situation_labels_test = torch.tensor(situation_labels_test)\n",
    "\n",
    "# âœ… 7. TensorDataset ìƒì„± (ì…ë ¥ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë ˆì´ë¸”ì„ ë¬¶ìŒ)\n",
    "input_ids_test = test_encodings['input_ids']\n",
    "attention_mask_test = test_encodings['attention_mask']\n",
    "token_type_ids_test = test_encodings['token_type_ids'] if 'token_type_ids' in test_encodings else torch.zeros_like(input_ids_test)\n",
    "\n",
    "# TensorDatasetì„ ì´ìš©í•´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ìƒì„±\n",
    "test_dataset = TensorDataset(input_ids_test, attention_mask_test, token_type_ids_test, emotion_labels_test, situation_labels_test)\n",
    "\n",
    "# âœ… 8. DataLoader ìƒì„± (ë°°ì¹˜ í¬ê¸° ì„¤ì •)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)  # ë°°ì¹˜ í¬ê¸° 16ìœ¼ë¡œ ì„¤ì •\n",
    "\n",
    "\n",
    "# âœ… 9. ë°°ì¹˜ ë°ì´í„° í™•ì¸ (ì„ íƒ ì‚¬í•­)\n",
    "for batch in train_dataloader:\n",
    "    print(batch)  # ì²« ë²ˆì§¸ ë°°ì¹˜ í™•ì¸\n",
    "    break  # ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ í™•ì¸\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    print(batch)  # ì²« ë²ˆì§¸ í…ŒìŠ¤íŠ¸ ë°°ì¹˜ í™•ì¸\n",
    "    break  # ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ í™•ì¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26ceb93-c004-405c-90ba-6b22cbf9f354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kj\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3227/3227 [08:09<00:00,  6.59it/s, Loss=4.6, Accuracy=0.252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 1/20 - Loss: 5.4871 - Accuracy: 0.2516 - Time: 489.42 sec\n",
      "âœ… ëª¨ë¸ì´ ê°œì„ ë˜ì–´ ì²´í¬í¬ì¸íŠ¸ ì €ì¥!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3227/3227 [08:08<00:00,  6.61it/s, Loss=4.85, Accuracy=0.324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Epoch 2/20 - Loss: 4.9178 - Accuracy: 0.3239 - Time: 488.12 sec\n",
      "âœ… ëª¨ë¸ì´ ê°œì„ ë˜ì–´ ì²´í¬í¬ì¸íŠ¸ ì €ì¥!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰            | 2226/3227 [05:37<02:30,  6.64it/s, Loss=5.06, Accuracy=0.372]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW, get_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "from datetime import datetime\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# âœ… 2. ëª¨ë¸ ìƒì„± (train_dfì˜ ê°ì •, ìƒí™© ë ˆì´ë¸” ìˆ˜ì— ë§ì¶° ì„¤ì •)\n",
    "num_emotions = len(train_df[\"emotion\"].unique())  # ê°ì • í´ë˜ìŠ¤ ê°œìˆ˜\n",
    "num_situations = len(train_df[\"situation\"].unique())  # ìƒí™© í´ë˜ìŠ¤ ê°œìˆ˜\n",
    "model_name = \"monologg/kobert\"\n",
    "\n",
    "model = KoBERTMultiOutput(model_name, num_emotions, num_situations)  # ëª¨ë¸ ì´ˆê¸°í™”\n",
    "\n",
    "# âœ… 3. ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU ë˜ëŠ” CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "model.to(device)  # ëª¨ë¸ì„ ì„¤ì •í•œ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
    "\n",
    "# âœ… 4. í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "emotion_labels = train_df['emotion'].values\n",
    "situation_labels = train_df['situation'].values\n",
    "\n",
    "# ê°ì •ê³¼ ìƒí™©ì— ëŒ€í•œ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "emotion_class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(emotion_labels), y=emotion_labels)\n",
    "situation_class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(situation_labels), y=situation_labels)\n",
    "\n",
    "# ê°€ì¤‘ì¹˜ë¥¼ í…ì„œë¡œ ë³€í™˜\n",
    "emotion_weights = torch.tensor(emotion_class_weights, dtype=torch.float).to(device)\n",
    "situation_weights = torch.tensor(situation_class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# âœ… 5. ì†ì‹¤ í•¨ìˆ˜ ì„¤ì • (ê°€ì¤‘ì¹˜ ì ìš©)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=emotion_weights)  # ê°ì • í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©\n",
    "situation_loss_fn = nn.CrossEntropyLoss(weight=situation_weights)  # ìƒí™© í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©\n",
    "\n",
    "# âœ… 6. ì˜µí‹°ë§ˆì´ì € ë° í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)  # AdamW ì˜µí‹°ë§ˆì´ì € ì‚¬ìš©\n",
    "num_training_steps = len(train_dataloader) * 20  # í•™ìŠµí•  ì´ ìŠ¤í… ìˆ˜ \n",
    "lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)  # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •\n",
    "\n",
    "# âœ… 7. ëª¨ë¸ í•™ìŠµ\n",
    "num_epochs = 20\n",
    "train_accuracy_history = []  # ì •í™•ë„ ê¸°ë¡\n",
    "train_loss_history = []  # ì†ì‹¤ê°’ ê¸°ë¡\n",
    "\n",
    "# ì–¼ë¦¬ìŠ¤íƒ‘ì„ ìœ„í•œ ë³€ìˆ˜ ì´ˆê¸°í™”\n",
    "best_accuracy = 0.0  # ê°€ì¥ ì¢‹ì€ ì •í™•ë„\n",
    "patience = 5  # ê°œì„ ë˜ì§€ ì•Šì•„ë„ í—ˆìš©í•  ì—í¬í¬ ìˆ˜\n",
    "early_stopping_counter = 0  # ì–¼ë¦¬ìŠ¤íƒ‘ ì¹´ìš´í„°\n",
    "\n",
    "# ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ì €ì¥ì„ ìœ„í•œ ê²½ë¡œ ì„¤ì •\n",
    "model_path = \"kobert_emotion_situation\"\n",
    "os.makedirs(model_path, exist_ok=True)  # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# âœ… 8. í•™ìŠµ ì‹œì‘\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì •\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    epoch_accuracy = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=True)\n",
    "\n",
    "    for batch in progress_bar:\n",
    "        # ë°°ì¹˜ ë°ì´í„°ë¥¼ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™\n",
    "        input_ids, attention_mask, token_type_ids, emotion_labels, situation_labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        token_type_ids = token_type_ids.to(device)\n",
    "        emotion_labels = emotion_labels.to(device)\n",
    "        situation_labels = situation_labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        emotion_logits, situation_logits = model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "        # ì†ì‹¤ ê³„ì‚° (ê°€ì¤‘ì¹˜ ì ìš©)\n",
    "        emotion_loss = loss_fn(emotion_logits, emotion_labels)\n",
    "        situation_loss = situation_loss_fn(situation_logits, situation_labels)\n",
    "\n",
    "        loss = emotion_loss + situation_loss\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()  # ê¸°ìš¸ê¸° ì´ˆê¸°í™”\n",
    "        loss.backward()  # ê¸°ìš¸ê¸° ê³„ì‚°\n",
    "        optimizer.step()  # ìµœì í™”\n",
    "        lr_scheduler.step()  # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸\n",
    "\n",
    "        total_loss += loss.item()  # ì†ì‹¤ê°’ ëˆ„ì \n",
    "\n",
    "        # ì •í™•ë„ ê³„ì‚°\n",
    "        emotion_pred = torch.argmax(emotion_logits, dim=1)\n",
    "        situation_pred = torch.argmax(situation_logits, dim=1)\n",
    "\n",
    "        correct += (emotion_pred == emotion_labels).sum().item()\n",
    "        correct += (situation_pred == situation_labels).sum().item()\n",
    "        total += emotion_labels.size(0) + situation_labels.size(0)\n",
    "\n",
    "        # ì •í™•ë„ ì—…ë°ì´íŠ¸\n",
    "        epoch_accuracy = correct / total\n",
    "\n",
    "        # ì§„í–‰ìƒí™©ì„ ë°”ì— ì†ì‹¤ê°’ê³¼ ì •í™•ë„ í‘œì‹œ\n",
    "        progress_bar.set_postfix({\"Loss\": loss.item(), \"Accuracy\": epoch_accuracy})\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)  # í‰ê·  ì†ì‹¤ ê³„ì‚°\n",
    "    epoch_accuracy = correct / total  # ì—í¬í¬ë³„ ì •í™•ë„ ê³„ì‚°\n",
    "\n",
    "    # ì—í¬í¬ë³„ ì†ì‹¤ê³¼ ì •í™•ë„ ê¸°ë¡\n",
    "    train_loss_history.append(avg_loss)\n",
    "    train_accuracy_history.append(epoch_accuracy)\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"âœ… Epoch {epoch+1}/{num_epochs} - Loss: {avg_loss:.4f} - Accuracy: {epoch_accuracy:.4f} - Time: {epoch_time:.2f} sec\")\n",
    "\n",
    "    # ì–¼ë¦¬ìŠ¤íƒ‘ ì¡°ê±´: ì„±ëŠ¥ì´ ê°œì„ ë˜ì§€ ì•Šìœ¼ë©´ í•™ìŠµì„ ì¤‘ì§€\n",
    "    if epoch_accuracy > best_accuracy:\n",
    "        best_accuracy = epoch_accuracy\n",
    "        early_stopping_counter = 0\n",
    "        # í˜„ì¬ ëª¨ë¸ì„ ì²´í¬í¬ì¸íŠ¸ë¡œ ì €ì¥\n",
    "        torch.save(model.state_dict(), f\"{model_path}/best_model.pth\")\n",
    "        print(\"âœ… ëª¨ë¸ì´ ê°œì„ ë˜ì–´ ì²´í¬í¬ì¸íŠ¸ ì €ì¥!\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        print(f\"âŒ ëª¨ë¸ ì„±ëŠ¥ì´ ê°œì„ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ì´ë¯¸ ê°œì„ ëœ íšŸìˆ˜: {early_stopping_counter})\")\n",
    "\n",
    "    # ì–¼ë¦¬ìŠ¤íƒ‘ ë°œë™ ì—¬ë¶€ í™•ì¸\n",
    "    if early_stopping_counter >= patience:\n",
    "        print(f\"âš ï¸ ì–¼ë¦¬ìŠ¤íƒ‘ ë°œë™! ì„±ëŠ¥ì´ ê°œì„ ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ìµœëŒ€ {patience} ì—í¬í¬)\")\n",
    "        break  # í•™ìŠµ ì¤‘ì§€\n",
    "\n",
    "print(\"ğŸ‰ KoBERT í•™ìŠµ ì™„ë£Œ!\")\n",
    "\n",
    "# âœ… ëª¨ë¸ ì €ì¥ (ìµœì¢… ëª¨ë¸ ê°€ì¤‘ì¹˜ ë° í•™ìŠµ ê¸°ë¡ í¬í•¨)\n",
    "torch.save(model.state_dict(), f\"{model_path}/final_model.pth\")  # ìµœì¢… ëª¨ë¸ ì €ì¥\n",
    "torch.save({'train_loss': train_loss_history, 'train_accuracy': train_accuracy_history}, f\"{model_path}/history.pth\")  # í•™ìŠµ ê¸°ë¡\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15896cc2-2187-45bd-9ad2-232a01e69641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
